{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "bFnLcrrbUft1",
        "outputId": "33358523-7561-4519-dfb7-8b4756396550"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'cuda'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 1
        }
      ],
      "source": [
        "import torch\n",
        "from torch import nn\n",
        "\n",
        "# Note: Pytorch 1.10.0 or latexr\n",
        "\n",
        "torch.__version__\n",
        "\n",
        "#SEt-up device-agnostic code\n",
        "device=\"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
        "device"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive # Mount my google drive diretory\n",
        "drive.mount(\"/content/gdrive\",force_remount=True)\n",
        "import os # Change directory to CS284 folder in google drive\n",
        "os.chdir(\"gdrive/MyDrive/Pruning_Study\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Ikg-x1asUhKx",
        "outputId": "1ecd8399-6e4b-44bf-85e2-0916f4f3fb87"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/gdrive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Dataset download an preparation"
      ],
      "metadata": {
        "id": "8yUiz3EgsWC-"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Downloads CIFAR-10 dataset. In this experiment, dataset is resized to 224x224 to match input size of the MobileNet V1 implementation."
      ],
      "metadata": {
        "id": "iX96PSz1syoi"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torchvision\n",
        "import torchvision.transforms as transforms\n",
        "\n",
        "\n",
        "import torch\n",
        "import torchvision\n",
        "import torchvision.transforms as transforms\n",
        "\n",
        "\n",
        "#Transform CIFAR10 to 224x224 with augmentation\n",
        "transform_train = transforms.Compose([\n",
        "    transforms.Resize(256),\n",
        "    transforms.RandomCrop(224),\n",
        "    transforms.RandomHorizontalFlip(),\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize((0.485, 0.456, 0.406), (0.229, 0.224, 0.225))\n",
        "])\n",
        "\n",
        "\n",
        "transform_test = transforms.Compose([\n",
        "    transforms.Resize(256),\n",
        "    transforms.CenterCrop(224),\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize((0.485, 0.456, 0.406), (0.229, 0.224, 0.225))\n",
        "])\n",
        "\n",
        "trainset = torchvision.datasets.CIFAR10(root='./CIFAR10', train=True,\n",
        "                                        download=True, transform=transform_train)\n",
        "testset = torchvision.datasets.CIFAR10(root='./CIFAR10', train=False,\n",
        "                                       download=True, transform=transform_test)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MagokX9_Uh9Y",
        "outputId": "cdb1ba1b-e2cb-4d13-d461-7f45265bc6c0"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Files already downloaded and verified\n",
            "Files already downloaded and verified\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Batch size and dataloader setting\n",
        "batch_size = 64\n",
        "train_dataloader = torch.utils.data.DataLoader(trainset, batch_size=batch_size,\n",
        "                                          shuffle=True, num_workers=2)\n",
        "test_dataloader = torch.utils.data.DataLoader(testset, batch_size=batch_size,\n",
        "                                         shuffle=False, num_workers=2)"
      ],
      "metadata": {
        "id": "uJ8HwmOFUjSX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "len(train_dataloader),len(test_dataloader)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HnrpuOKrUkqP",
        "outputId": "6bc99e36-a99e-4362-9899-8c221950cfc9"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(782, 157)"
            ]
          },
          "metadata": {},
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "img,label=next(iter(train_dataloader))\n",
        "\n",
        "img.shape,label[0]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FKuiGjsLUl4t",
        "outputId": "ed7837e4-0619-48c6-c42d-eb40fe9d6cf9"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(torch.Size([64, 3, 224, 224]), tensor(9))"
            ]
          },
          "metadata": {},
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Full Model"
      ],
      "metadata": {
        "id": "8xn4RZRqUoSR"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "MobileNet V1 implementation is based from here: https://medium.com/@karuneshu21/implement-mobilenet-v1-in-pytorch-fd03a6618321\n",
        "\n",
        "The implementation is modified to only have 10 classes as we are only using CIFAR-10 Dataset"
      ],
      "metadata": {
        "id": "NXSn_PuZsaLw"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "# all nn libraries nn.layer, convs and loss functions\n",
        "\n",
        "import torch.nn as nn\n",
        "# Display Image\n",
        "\n",
        "from IPython.display import Image\n",
        "\n",
        "# visualisation\n",
        "!pip install torchview\n",
        "import torchvision\n",
        "from torchview import draw_graph\n",
        "\n",
        "# !pip install transformers\n",
        "#from transformers import MobileNetV1Config, MobileNetV1Model\n",
        "\n",
        "# set device\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "print(device)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NgMMRFNaU4tg",
        "outputId": "e986a732-0c91-4cb1-de3c-83c457814af5"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting torchview\n",
            "  Downloading torchview-0.2.6-py3-none-any.whl (25 kB)\n",
            "Installing collected packages: torchview\n",
            "Successfully installed torchview-0.2.6\n",
            "cuda\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Depthwise example\n",
        "\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "\n",
        "# Define a simple depthwise convolutional layer\n",
        "class DepthwiseConv2d(nn.Module):\n",
        "    def __init__(self, in_channels, kernel_size, stride=1, padding=0):\n",
        "        super(DepthwiseConv2d, self).__init__()\n",
        "        self.depthwise = nn.Conv2d(in_channels, in_channels, kernel_size, stride=stride, padding=padding, groups=in_channels)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.depthwise(x)\n",
        "        return x\n",
        "\n",
        "# Example usage\n",
        "# Create a random input tensor\n",
        "input_tensor = torch.randn(1, 3, 32, 32)  # (batch_size, channels, height, width)\n",
        "\n",
        "# Define a depthwise convolutional layer\n",
        "depthwise_conv = DepthwiseConv2d(in_channels=3, kernel_size=3, stride=1, padding=1)\n",
        "\n",
        "# Apply the depthwise convolution to the input tensor\n",
        "output_tensor = depthwise_conv(input_tensor)\n",
        "\n",
        "# Print the shape of the output tensor\n",
        "print(\"Output tensor shape:\", output_tensor.shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mbb9tjJwU7TY",
        "outputId": "d6bc55a1-ac1a-438c-a12d-b0ab23489b65"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Output tensor shape: torch.Size([1, 3, 32, 32])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "\n",
        "# Define a simple pointwise convolutional layer\n",
        "class PointwiseConv2d(nn.Module):\n",
        "    def __init__(self, in_channels, out_channels, kernel_size=1, stride=1, padding=0):\n",
        "        super(PointwiseConv2d, self).__init__()\n",
        "        self.pointwise = nn.Conv2d(in_channels, out_channels, kernel_size, stride=stride, padding=padding)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.pointwise(x)\n",
        "        return x\n",
        "\n",
        "# Example usage\n",
        "# Create a random input tensor\n",
        "input_tensor = torch.randn(1, 3, 32, 32)  # (batch_size, channels, height, width)\n",
        "\n",
        "# Define a pointwise convolutional layer\n",
        "pointwise_conv = PointwiseConv2d(in_channels=3, out_channels=64)\n",
        "\n",
        "# Apply the pointwise convolution to the input tensor\n",
        "output_tensor = pointwise_conv(input_tensor)\n",
        "\n",
        "# Print the shape of the output tensor\n",
        "print(\"Output tensor shape:\", output_tensor.shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1p2lkG1PU9fA",
        "outputId": "c81d9bff-e042-4926-b412-53520c8bcb05"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Output tensor shape: torch.Size([1, 64, 32, 32])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "class DepthWiseSeperable(nn.Module):\n",
        "\n",
        "    def __init__(self, in_channels , out_channels , stride ):\n",
        "        \"\"\"\n",
        "        DepthWiseSeperable block of MobileNet which performs the following operations:\n",
        "        (a) depthwise convolution by applying a separate filter for each channel\n",
        "        (b) pointwise convolutions are applied which combine the filtered result by implementing 1 × 1 convolution\n",
        "\n",
        "            Note:\n",
        "                1. groups = in_channels used for depthwise convolution\n",
        "                2. in_channels and out_channels are same for depthwise convolution\n",
        "                3. bias = False due to the usage of BatchNorm\n",
        "                4. To generate same height and width of output feature map as the input feature map, following should be padding for\n",
        "                    * 1x1 conv : p=0\n",
        "                    * 3x3 conv : p=1\n",
        "                    * 5x5 conv : p=2\n",
        "\n",
        "\n",
        "        Args:\n",
        "          in_channels (int) : number of input channels\n",
        "          out_channels (int) : number of output channels\n",
        "          stride (int) : stride used for depthwise convolution\n",
        "\n",
        "        Attributes:\n",
        "            Depthwise seperable convolutional block\n",
        "\n",
        "        \"\"\"\n",
        "\n",
        "        super(DepthWiseSeperable,self).__init__()\n",
        "\n",
        "        # groups used here\n",
        "        self.depthwise = nn.Conv2d(in_channels = in_channels , out_channels = in_channels , stride = stride , padding = 1, kernel_size = 3 , groups=in_channels , bias = False)\n",
        "        self.bn1 = nn.BatchNorm2d(in_channels)\n",
        "\n",
        "        self.pointwise = nn.Conv2d(in_channels = in_channels , out_channels = out_channels , stride = 1 , padding = 0, kernel_size = 1, bias = False)\n",
        "        self.bn2 = nn.BatchNorm2d(out_channels)\n",
        "\n",
        "        self.relu = nn.ReLU()\n",
        "\n",
        "    def forward(self,x):\n",
        "\n",
        "        x = self.depthwise(x)\n",
        "        x = self.bn1(x)\n",
        "        x = self.relu(x)\n",
        "\n",
        "        x = self.pointwise(x)\n",
        "        x = self.bn2(x)\n",
        "        x = self.relu(x)\n",
        "\n",
        "        return x\n",
        "\n",
        "\n",
        "def test_DepthWiseSeperable():\n",
        "    x = torch.randn(1,32,112,112)\n",
        "    model = DepthWiseSeperable(32,64,2)\n",
        "    print(model(x).shape)\n",
        "\n",
        "    return model\n",
        "\n",
        "\n",
        "#model = test_DepthWiseSeperable()\n",
        "#architecture = 'DepthWiseSeperable'\n",
        "#model_graph = draw_graph(model, input_size=(1,32,112,112), graph_dir ='TB' , roll=True, expand_nested=True, graph_name=f'self_{architecture}',save_graph=True,filename=f'self_{architecture}')\n",
        "#model_graph.visual_graph\n",
        "\n",
        "# output\n",
        "\"\"\"\n",
        "torch.Size([1, 64, 56, 56])\n",
        "\"\"\""
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "_T14PCW_VAFe",
        "outputId": "0370d446-e777-47cb-fac0-b1ccb97508fe"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'\\ntorch.Size([1, 64, 56, 56])\\n'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "test=img\n",
        "test.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TQ02mMcfVCdx",
        "outputId": "e3e8ea23-d5f8-453a-c8a3-be91931958ce"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([64, 3, 224, 224])"
            ]
          },
          "metadata": {},
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "class MobileNetV1(nn.Module):\n",
        "\n",
        "    def __init__(self, num_classes=10):\n",
        "\n",
        "        super(MobileNetV1, self).__init__()\n",
        "\n",
        "        # Initial convolution layer\n",
        "        self.features1 = nn.Sequential(\n",
        "            nn.Conv2d(3, 32, kernel_size=3, stride=2, padding=1, bias = False),\n",
        "            nn.ReLU(inplace=True),\n",
        "            nn.BatchNorm2d(32),\n",
        "        )\n",
        "\n",
        "        # Depthwise separable convolutions\n",
        "        self.features2 = DepthWiseSeperable(32, 64, 1)\n",
        "        self.features3 = DepthWiseSeperable(64, 128, 2)\n",
        "        self.features4 = DepthWiseSeperable(128, 128, 1)\n",
        "        self.features5 = DepthWiseSeperable(128, 256, 2)\n",
        "\n",
        "        self.features6 = DepthWiseSeperable(256, 256, 1)\n",
        "        self.features7 = DepthWiseSeperable(256, 512, 2)\n",
        "        self.features8 = DepthWiseSeperable(512, 512, 1)\n",
        "        self.features9 = DepthWiseSeperable(512, 512, 1)\n",
        "        self.features10 = DepthWiseSeperable(512, 512, 1)\n",
        "        self.features11 = DepthWiseSeperable(512, 512, 1)\n",
        "        self.features12 = DepthWiseSeperable(512, 512, 1)\n",
        "        self.features13 = DepthWiseSeperable(512, 1024, 2)\n",
        "        self.features14 = DepthWiseSeperable(1024, 1024, 1)\n",
        "\n",
        "\n",
        "        # Average pooling and classifier\n",
        "        self.avgpool = nn.AdaptiveAvgPool2d(1)\n",
        "        self.classifier = nn.Sequential(\n",
        "            nn.Linear(1024, num_classes),\n",
        "        )\n",
        "\n",
        "    def forward(self, x):\n",
        "        x=  self.features1(x)\n",
        "        x = self.features2(x)\n",
        "        x = self.features3(x)\n",
        "        x = self.features4(x)\n",
        "        x = self.features5(x)\n",
        "        x = self.features6(x)\n",
        "        x = self.features7(x)\n",
        "        x = self.features8(x)\n",
        "        x = self.features9(x)\n",
        "        x = self.features10(x)\n",
        "        x = self.features11(x)\n",
        "        x = self.features12(x)\n",
        "        x = self.features13(x)\n",
        "        x = self.features14(x)\n",
        "        x = self.avgpool(x)\n",
        "        x = x.view(x.size(0), -1)\n",
        "        x = self.classifier(x)\n",
        "        return x\n",
        "\n",
        "\n",
        "# Create an instance of MobileNetV1\n",
        "model = MobileNetV1()\n",
        "# print(model)\n",
        "\n",
        "\n",
        "def test_Mobilenet():\n",
        "    x = torch.randn(1,3,224,224)\n",
        "    model = MobileNetV1()\n",
        "    print(model(x).shape)\n",
        "\n",
        "    return model\n",
        "\n",
        "\n",
        "#model = test_Mobilenet()\n",
        "#architecture = 'mobilenetv1'\n",
        "#model_graph = draw_graph(model, input_size=(1,3,64,64), graph_dir ='TB' , roll=True, expand_nested=True, graph_name=f'self_{architecture}',save_graph=True,filename=f'self_{architecture}')\n",
        "# model_graph.visual_graph"
      ],
      "metadata": {
        "id": "hjVCUa7WVDSp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "test=img\n",
        "test.shape\n",
        "model_big=MobileNetV1()\n",
        "test_input=test\n",
        "test_input.shape\n",
        "test_model=model_big(test_input)\n",
        "test_model.shape\n",
        "total_params = sum(p.numel() for p in model.parameters())\n",
        "print(\"Total number of parameters: \", total_params)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "89sspvc3Wfph",
        "outputId": "5ffe92cd-1661-449e-8c33-f71841134835"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Total number of parameters:  3217226\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Import time it for training time checking and printing of total time\n",
        "from timeit import default_timer as timer\n",
        "def print_train_time(start:float,end:float,device:torch.device=None):\n",
        "  total_time=end-start\n",
        "  print(f\"Train time on {device}: {total_time:.3f} seconds\")\n",
        "  return total_time\n",
        "\n",
        "def print_test_time(start:float,end:float,device:torch.device=None):\n",
        "  total_time=end-start\n",
        "  print(f\"Test time on {device}: {total_time:.3f} seconds\")\n",
        "  return total_time\n",
        "\n",
        "# Function made for accuracy checking\n",
        "def accuracy_fn(y_target,y_pred):\n",
        "\n",
        "    correct = (y_target==y_pred).sum().item()\n",
        "    acc = (correct / len(y_pred)) * 100\n",
        "    return acc\n"
      ],
      "metadata": {
        "id": "8XnkmKL0XvI8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Training from scratch\n",
        "from torch.optim.lr_scheduler import CosineAnnealingLR\n",
        "\n",
        "device=\"cuda\" if torch.cuda.is_available() else \"cpu\" #device\n",
        "loss_fn=nn.CrossEntropyLoss()#Loss Function\n",
        "\n",
        "model_big=MobileNetV1()\n",
        "optimizer1=torch.optim.Adam(params=model_big.parameters(),lr=0.0005,weight_decay=0.001) #Optimizer\n",
        "\n",
        "\n",
        "lr_scheduler = CosineAnnealingLR(optimizer1, T_max=500)\n",
        "sigmoid=nn.Sigmoid()"
      ],
      "metadata": {
        "id": "ayVdfB9DXMet"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from torch.utils.data import DataLoader"
      ],
      "metadata": {
        "id": "y6vmHnVgXNq1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Training and Testing Function\n",
        "def training(model:torch.nn.Module,data_loader:DataLoader,loss_fn:torch.nn.Module,optimizer:torch.optim.Optimizer, accuracy_fn,device:torch.device=device):\n",
        "  train_loss,train_acc=0,0\n",
        "  model.to(device)\n",
        "  model.train()\n",
        "\n",
        "  for batch,(X,y) in enumerate(data_loader):\n",
        "    X,y=X.float().to(device),y.to(device)\n",
        "\n",
        "    y_pred=model(X)\n",
        "\n",
        "    loss=loss_fn(y_pred,y)\n",
        "    y_pred_class=torch.argmax(torch.softmax(y_pred,dim=1),dim=1)\n",
        "    train_loss=train_loss+loss\n",
        "\n",
        "    train_acc=train_acc+accuracy_fn(y_target=y,y_pred=y_pred_class)\n",
        "    optimizer.zero_grad()\n",
        "\n",
        "    loss.backward()\n",
        "\n",
        "    optimizer.step()\n",
        "  lr_scheduler.step()\n",
        "\n",
        "  train_loss/=len(data_loader)\n",
        "  train_acc/=len(data_loader)\n",
        "  print(f\"Train Loss:{train_loss:5f}|Train Acc:{train_acc:5f}%\")\n",
        "  return train_loss,train_acc\n",
        "\n",
        "\n",
        "def testing(data_loader:DataLoader,model:torch.nn.Module,loss_fn:torch.nn.Module,accuracy_fn,device:torch.device=device):\n",
        "  test_loss,test_acc=0,0\n",
        "  model.to(device)\n",
        "  model.eval()\n",
        "\n",
        "  with torch.inference_mode():\n",
        "    for X,y in data_loader:\n",
        "      X,y=X.float().to(device),y.to(device)\n",
        "\n",
        "      test_pred=model(X)\n",
        "\n",
        "      test_loss=test_loss+loss_fn(test_pred,y)\n",
        "      y_pred_class=torch.argmax(torch.softmax(test_pred,dim=1),dim=1)\n",
        "      test_acc=test_acc+accuracy_fn(y_target=y,y_pred=y_pred_class)\n",
        "\n",
        "    test_loss/=len(data_loader)\n",
        "    test_acc/=len(data_loader)\n",
        "\n",
        "    print(f\"Test loss: {test_loss:.5f} | Test accuracy: {test_acc:.2f}%\\n\")\n",
        "\n",
        "    return test_loss,test_acc"
      ],
      "metadata": {
        "id": "SItvUlejXHdz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "##Training and Testing Loop\n",
        "\n",
        "\n",
        "#Training Loop\n",
        "\n",
        "from tqdm.auto import tqdm\n",
        "import torch\n",
        "\n",
        "train_loss_list=[]\n",
        "train_acc_list=[]\n",
        "test_loss_list=[]\n",
        "test_acc_list=[]\n",
        "\n",
        "epochs=50 #epochs\n",
        "best_acc=0\n",
        "patience=70\n",
        "max_patience_after_revert = 30\n",
        "current_patience=0\n",
        "\n",
        "from pathlib import Path\n",
        "model_path=Path(\"models\")\n",
        "model_path.mkdir(parents=True,exist_ok=True)\n",
        "model_name=\"best_model_big.pth\" #modelname\n",
        "model_save_path=model_path/model_name\n",
        "\n",
        "\n",
        "\n",
        "# Create model save\n",
        "\n",
        "\n",
        "reverted=False\n",
        "start_timer=timer()\n",
        "for epoch in tqdm(range(epochs)):\n",
        "  print(f\"Epoch:{epoch}\")\n",
        "  train_loss,train_acc=training(data_loader=train_dataloader,model=model_big,loss_fn=loss_fn,optimizer=optimizer1,accuracy_fn=accuracy_fn)\n",
        "  test_loss,test_acc=testing(data_loader=test_dataloader,model=model_big,loss_fn=loss_fn,accuracy_fn=accuracy_fn)\n",
        "\n",
        "\n",
        "  if (test_acc>best_acc):\n",
        "    best_acc=test_acc\n",
        "    model_big.state_dict()\n",
        "    best_model_state_dict=model.state_dict()\n",
        "    torch.save(model_big.state_dict(),f=model_save_path)\n",
        "    print(f\"New best test acc is {test_acc}. Model Saved\")\n",
        "    current_patience=0 #reset patience\n",
        "    patience_after_revert=0\n",
        "    reverted=False\n",
        "  else:\n",
        "    current_patience+=1\n",
        "\n",
        "    if current_patience>=patience and not reverted:\n",
        "      print(f\"No improvement for{patience} epochs. Reverting to the best model\")\n",
        "      model.load_state_dict(best_model_state_dict)\n",
        "      patience_after_revert=0\n",
        "      reverted=True\n",
        "\n",
        "  if reverted:\n",
        "    patience_after_revert+=1\n",
        "    if patience_after_revert>=max_patience_after_revert:\n",
        "      print(f\"Continue for {max_patience_after_revert} epochs after revert\")\n",
        "\n",
        "      if test_acc>=best_acc:\n",
        "       print(\"Test loss still not improving reverting to best model\")\n",
        "       model.load_state_dict(best_model_state_dict)\n",
        "      patience_after_revert=0\n",
        "\n",
        "\n",
        "from pathlib import Path\n",
        "model_path=Path(\"models\")\n",
        "model_path.mkdir(parents=True,exist_ok=True)\n",
        "model_name=\"last_model_big.pth\" #modelname\n",
        "model_save_path=model_path/model_name\n",
        "# Create model save\n",
        "\n",
        "\n",
        "torch.save(model_big.state_dict(),f=model_save_path)\n",
        "print(f\"Last model is saved with test loss:{test_acc}\")\n",
        "model_big.state_dict()\n",
        "\n",
        "end_timer=timer()\n",
        "print_train_time(start=start_timer,end=end_timer,device=device)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000,
          "referenced_widgets": [
            "006df9d8816e4e349ebd239b9303ebba",
            "824409171e4d404281223828ce1861e3",
            "ed9c6c532ffd4721b6be57776849b38a",
            "2361a93e60d748798c769167211129aa",
            "2a53a3d1822c425b8a0ec8587696cc97",
            "00504582ef41489f94a5c7f487104cbc",
            "60090060fb8c482db4a2b1114b2ecfa9",
            "3d64e7eed9a94fc6a31df2bd402f1d2c",
            "041f8de0cc6e4f66b21f73640b385ed1",
            "38e9461d5b69451d9cd216fdc87a0b2b",
            "2e3b68d1037e48cbaf0b6a0be85130d5"
          ]
        },
        "id": "k-YTbwsbXP1_",
        "outputId": "71b189c0-f6b8-4105-fa30-cae115a3fd34"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "  0%|          | 0/50 [00:00<?, ?it/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "006df9d8816e4e349ebd239b9303ebba"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train Loss:1.382474|Train Acc:49.514466%\n",
            "Test loss: 1.06938 | Test accuracy: 61.84%\n",
            "\n",
            "Epoch:0\n",
            "New best test acc is 61.843152866242036. Model Saved\n",
            "Train Loss:0.958583|Train Acc:65.956682%\n",
            "Test loss: 0.89568 | Test accuracy: 69.07%\n",
            "\n",
            "Epoch:1\n",
            "New best test acc is 69.06847133757962. Model Saved\n",
            "Train Loss:0.748709|Train Acc:74.162804%\n",
            "Test loss: 0.74090 | Test accuracy: 74.45%\n",
            "\n",
            "Epoch:2\n",
            "New best test acc is 74.45262738853503. Model Saved\n",
            "Train Loss:0.640238|Train Acc:78.041081%\n",
            "Test loss: 0.61733 | Test accuracy: 79.03%\n",
            "\n",
            "Epoch:3\n",
            "New best test acc is 79.03065286624204. Model Saved\n",
            "Train Loss:0.568183|Train Acc:80.600623%\n",
            "Test loss: 0.58644 | Test accuracy: 80.00%\n",
            "\n",
            "Epoch:4\n",
            "New best test acc is 79.99601910828025. Model Saved\n",
            "Train Loss:0.514935|Train Acc:82.498801%\n",
            "Test loss: 0.53230 | Test accuracy: 81.94%\n",
            "\n",
            "Epoch:5\n",
            "New best test acc is 81.93670382165605. Model Saved\n",
            "Train Loss:0.475566|Train Acc:83.773577%\n",
            "Test loss: 0.48668 | Test accuracy: 83.58%\n",
            "\n",
            "Epoch:6\n",
            "New best test acc is 83.57882165605096. Model Saved\n",
            "Train Loss:0.444797|Train Acc:84.896499%\n",
            "Test loss: 0.46143 | Test accuracy: 83.97%\n",
            "\n",
            "Epoch:7\n",
            "New best test acc is 83.96695859872611. Model Saved\n",
            "Train Loss:0.420597|Train Acc:85.583840%\n",
            "Test loss: 0.45278 | Test accuracy: 84.50%\n",
            "\n",
            "Epoch:8\n",
            "New best test acc is 84.50437898089172. Model Saved\n",
            "Train Loss:0.399628|Train Acc:86.391065%\n",
            "Test loss: 0.45181 | Test accuracy: 84.61%\n",
            "\n",
            "Epoch:9\n",
            "New best test acc is 84.61385350318471. Model Saved\n",
            "Train Loss:0.387063|Train Acc:86.848625%\n",
            "Test loss: 0.44571 | Test accuracy: 85.01%\n",
            "\n",
            "Epoch:10\n",
            "New best test acc is 85.01194267515923. Model Saved\n",
            "Train Loss:0.365533|Train Acc:87.719789%\n",
            "Test loss: 0.41895 | Test accuracy: 86.00%\n",
            "\n",
            "Epoch:11\n",
            "New best test acc is 85.99721337579618. Model Saved\n",
            "Train Loss:0.352863|Train Acc:87.937580%\n",
            "Test loss: 0.40103 | Test accuracy: 86.20%\n",
            "\n",
            "Epoch:12\n",
            "New best test acc is 86.19625796178345. Model Saved\n",
            "Train Loss:0.341523|Train Acc:88.373162%\n",
            "Test loss: 0.40258 | Test accuracy: 86.47%\n",
            "\n",
            "Epoch:13\n",
            "New best test acc is 86.4749203821656. Model Saved\n",
            "Train Loss:0.333097|Train Acc:88.688859%\n",
            "Test loss: 0.40106 | Test accuracy: 86.48%\n",
            "\n",
            "Epoch:14\n",
            "New best test acc is 86.48487261146497. Model Saved\n",
            "Train Loss:0.321568|Train Acc:89.222347%\n",
            "Test loss: 0.39210 | Test accuracy: 86.68%\n",
            "\n",
            "Epoch:15\n",
            "New best test acc is 86.68391719745223. Model Saved\n",
            "Train Loss:0.315014|Train Acc:89.354220%\n",
            "Test loss: 0.37413 | Test accuracy: 87.73%\n",
            "\n",
            "Epoch:16\n",
            "New best test acc is 87.72890127388536. Model Saved\n",
            "Train Loss:0.306392|Train Acc:89.621963%\n",
            "Test loss: 0.37858 | Test accuracy: 87.03%\n",
            "\n",
            "Epoch:17\n",
            "Train Loss:0.300305|Train Acc:89.675911%\n",
            "Test loss: 0.36535 | Test accuracy: 87.47%\n",
            "\n",
            "Epoch:18\n",
            "Train Loss:0.290171|Train Acc:90.191416%\n",
            "Test loss: 0.37833 | Test accuracy: 87.28%\n",
            "\n",
            "Epoch:19\n",
            "Train Loss:0.285598|Train Acc:90.203405%\n",
            "Test loss: 0.36651 | Test accuracy: 87.78%\n",
            "\n",
            "Epoch:20\n",
            "New best test acc is 87.77866242038216. Model Saved\n",
            "Train Loss:0.276153|Train Acc:90.617008%\n",
            "Test loss: 0.34907 | Test accuracy: 88.37%\n",
            "\n",
            "Epoch:21\n",
            "New best test acc is 88.36584394904459. Model Saved\n",
            "Train Loss:0.275042|Train Acc:90.726902%\n",
            "Test loss: 0.33979 | Test accuracy: 88.53%\n",
            "\n",
            "Epoch:22\n",
            "New best test acc is 88.5250796178344. Model Saved\n",
            "Train Loss:0.271420|Train Acc:90.962676%\n",
            "Test loss: 0.38443 | Test accuracy: 87.03%\n",
            "\n",
            "Epoch:23\n",
            "Train Loss:0.267437|Train Acc:90.970668%\n",
            "Test loss: 0.31809 | Test accuracy: 89.38%\n",
            "\n",
            "Epoch:24\n",
            "New best test acc is 89.38097133757962. Model Saved\n",
            "Train Loss:0.258401|Train Acc:91.334319%\n",
            "Test loss: 0.33648 | Test accuracy: 88.68%\n",
            "\n",
            "Epoch:25\n",
            "Train Loss:0.262917|Train Acc:91.036605%\n",
            "Test loss: 0.36911 | Test accuracy: 87.58%\n",
            "\n",
            "Epoch:26\n",
            "Train Loss:0.249277|Train Acc:91.486173%\n",
            "Test loss: 0.34319 | Test accuracy: 87.97%\n",
            "\n",
            "Epoch:27\n",
            "Train Loss:0.251642|Train Acc:91.370285%\n",
            "Test loss: 0.36046 | Test accuracy: 87.83%\n",
            "\n",
            "Epoch:28\n",
            "Train Loss:0.246357|Train Acc:91.656010%\n",
            "Test loss: 0.35381 | Test accuracy: 88.22%\n",
            "\n",
            "Epoch:29\n",
            "Train Loss:0.244826|Train Acc:91.689978%\n",
            "Test loss: 0.33378 | Test accuracy: 88.49%\n",
            "\n",
            "Epoch:30\n",
            "Train Loss:0.238206|Train Acc:92.081602%\n",
            "Test loss: 0.35372 | Test accuracy: 87.93%\n",
            "\n",
            "Epoch:31\n",
            "Train Loss:0.239921|Train Acc:91.897778%\n",
            "Test loss: 0.33912 | Test accuracy: 88.77%\n",
            "\n",
            "Epoch:32\n",
            "Train Loss:0.236558|Train Acc:92.015665%\n",
            "Test loss: 0.34589 | Test accuracy: 88.68%\n",
            "\n",
            "Epoch:33\n",
            "Train Loss:0.232989|Train Acc:92.041640%\n",
            "Test loss: 0.32628 | Test accuracy: 88.99%\n",
            "\n",
            "Epoch:34\n",
            "Train Loss:0.231621|Train Acc:92.159527%\n",
            "Test loss: 0.34766 | Test accuracy: 88.52%\n",
            "\n",
            "Epoch:35\n",
            "Train Loss:0.228182|Train Acc:92.321371%\n",
            "Test loss: 0.36144 | Test accuracy: 87.69%\n",
            "\n",
            "Epoch:36\n",
            "Train Loss:0.222877|Train Acc:92.481218%\n",
            "Test loss: 0.34874 | Test accuracy: 88.20%\n",
            "\n",
            "Epoch:37\n",
            "Train Loss:0.226182|Train Acc:92.329364%\n",
            "Test loss: 0.35118 | Test accuracy: 88.19%\n",
            "\n",
            "Epoch:38\n",
            "Train Loss:0.222431|Train Acc:92.515185%\n",
            "Test loss: 0.32337 | Test accuracy: 89.26%\n",
            "\n",
            "Epoch:39\n",
            "Train Loss:0.219461|Train Acc:92.671036%\n",
            "Test loss: 0.31965 | Test accuracy: 89.49%\n",
            "\n",
            "Epoch:40\n",
            "New best test acc is 89.49044585987261. Model Saved\n",
            "Train Loss:0.214553|Train Acc:92.794917%\n",
            "Test loss: 0.30925 | Test accuracy: 89.23%\n",
            "\n",
            "Epoch:41\n",
            "Train Loss:0.215867|Train Acc:92.770940%\n",
            "Test loss: 0.31812 | Test accuracy: 89.47%\n",
            "\n",
            "Epoch:42\n",
            "Train Loss:0.214505|Train Acc:92.810902%\n",
            "Test loss: 0.32630 | Test accuracy: 89.07%\n",
            "\n",
            "Epoch:43\n",
            "Train Loss:0.213331|Train Acc:92.860854%\n",
            "Test loss: 0.31639 | Test accuracy: 89.44%\n",
            "\n",
            "Epoch:44\n",
            "Train Loss:0.213749|Train Acc:92.766944%\n",
            "Test loss: 0.33079 | Test accuracy: 89.28%\n",
            "\n",
            "Epoch:45\n",
            "Train Loss:0.208032|Train Acc:92.942775%\n",
            "Test loss: 0.32352 | Test accuracy: 89.43%\n",
            "\n",
            "Epoch:46\n",
            "Train Loss:0.211741|Train Acc:92.874840%\n",
            "Test loss: 0.33671 | Test accuracy: 88.87%\n",
            "\n",
            "Epoch:47\n",
            "Train Loss:0.206350|Train Acc:93.124600%\n",
            "Test loss: 0.30847 | Test accuracy: 89.73%\n",
            "\n",
            "Epoch:48\n",
            "New best test acc is 89.72929936305732. Model Saved\n",
            "Train Loss:0.202968|Train Acc:93.080643%\n",
            "Test loss: 0.32520 | Test accuracy: 89.42%\n",
            "\n",
            "Epoch:49\n",
            "Last model is saved with test loss:89.42078025477707\n",
            "Train time on cuda: 5028.271 seconds\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "5028.270874894"
            ]
          },
          "metadata": {},
          "execution_count": 18
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Loading trained model\n",
        "def testing(data_loader:DataLoader,model:torch.nn.Module,loss_fn:torch.nn.Module,accuracy_fn,device:torch.device=device):\n",
        "  test_loss,test_acc=0,0\n",
        "  model.to(device)\n",
        "  model.eval()\n",
        "\n",
        "  with torch.inference_mode():\n",
        "    for X,y in data_loader:\n",
        "      X,y=X.float().to(device),y.to(device)\n",
        "\n",
        "      test_pred=model(X)\n",
        "\n",
        "      test_loss=test_loss+loss_fn(test_pred,y)\n",
        "      y_pred_class=torch.argmax(torch.softmax(test_pred,dim=1),dim=1)\n",
        "      test_acc=test_acc+accuracy_fn(y_target=y,y_pred=y_pred_class)\n",
        "\n",
        "    test_loss/=len(data_loader)\n",
        "    test_acc/=len(data_loader)\n",
        "\n",
        "    print(f\"Test loss: {test_loss:.5f} | Test accuracy: {test_acc:.2f}%\\n\")\n",
        "\n",
        "    return test_loss,test_acc\n",
        "\n",
        "# This is when conitnuing training of a previously saved model\n",
        "from pathlib import Path\n",
        "model_path=Path(\"models\")\n",
        "model_path.mkdir(parents=True,exist_ok=True)\n",
        "model_name=\"best_model_big_07052024.pth\" #modelname\n",
        "model_save_path=model_path/model_name\n",
        "\n",
        "#Load testing\n",
        "sigmoid=nn.Sigmoid()\n",
        "loss_fn=nn.CrossEntropyLoss()#Loss Function\n",
        "\n",
        "\n",
        "\n",
        "model_big=MobileNetV1()\n",
        "model_big.load_state_dict(torch.load(f=model_save_path))\n",
        "#model_load.state_dict()\n",
        "optimizer1=torch.optim.Adam(params=model_big.parameters(),lr=0.0005,weight_decay=0.000) #Optimizer\n",
        "\n",
        "\n",
        "lr_scheduler = CosineAnnealingLR(optimizer1, T_max=500)\n",
        "start_timer=timer()\n",
        "test_loss,test_acc=testing(data_loader=test_dataloader,model=model_big,loss_fn=loss_fn,accuracy_fn=accuracy_fn)\n",
        "\n",
        "best_loss=test_loss\n",
        "best_loss\n",
        "end_timer=timer()\n",
        "print_test_time(start=start_timer,end=end_timer,device=device)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Aei4T1CLhJgO",
        "outputId": "72b665a6-942d-4901-adc1-b17f5ce6aaf3"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Test loss: 0.30847 | Test accuracy: 89.73%\n",
            "\n",
            "Test time on cuda: 9.679 seconds\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "9.67883318500003"
            ]
          },
          "metadata": {},
          "execution_count": 31
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "\n",
        "def get_scaling_factors(network):\n",
        "    scaling_factors = []\n",
        "    for module in network.modules():\n",
        "        if isinstance(module, nn.BatchNorm2d) or isinstance(module, nn.BatchNorm1d):\n",
        "            scaling_factors.append(module.weight)\n",
        "    return scaling_factors\n",
        "scaling_factors=get_scaling_factors(model_big)\n",
        "scaling_factors[2],max(scaling_factors[2]),min(scaling_factors[2])\n"
      ],
      "metadata": {
        "id": "qp0vczq6pyH7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Pruned"
      ],
      "metadata": {
        "id": "gOIr8S17hO4y"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "The Network is pruned. 5 blocks are removed and are replaced with 2 smaller blocks."
      ],
      "metadata": {
        "id": "rTUItOj4uLQR"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class MobileNetV1_prunedblock6(nn.Module):\n",
        "\n",
        "    def __init__(self, num_classes=10):\n",
        "\n",
        "        super(MobileNetV1_prunedblock6, self).__init__()\n",
        "\n",
        "        # Initial convolution layer\n",
        "        self.features1 = nn.Sequential(\n",
        "            nn.Conv2d(3, 32, kernel_size=3, stride=2, padding=1, bias = False),\n",
        "            nn.ReLU(inplace=True),\n",
        "            nn.BatchNorm2d(32),\n",
        "        )\n",
        "\n",
        "        # Depthwise separable convolutions\n",
        "        self.features2 = DepthWiseSeperable(32, 64, 1)\n",
        "        self.features3 = DepthWiseSeperable(64, 128, 2)\n",
        "        self.features4 = DepthWiseSeperable(128, 128, 1)\n",
        "        self.features5 = DepthWiseSeperable(128, 256, 2)\n",
        "\n",
        "        self.features6 = DepthWiseSeperable(256, 256, 1)\n",
        "        self.features7 = DepthWiseSeperable(256, 512, 2)\n",
        "        self.features8 = DepthWiseSeperable(512, 64, 1)\n",
        "        self.features9 = DepthWiseSeperable(64, 32, 1)\n",
        "        ##self.features10 = DepthWiseSeperable(512, 512, 1)\n",
        "        ##self.features11 = DepthWiseSeperable(512, 512, 1)\n",
        "        ##self.features12 = DepthWiseSeperable(512, 512, 1)\n",
        "        ##self.features13 = DepthWiseSeperable(512, 1024, 2)\n",
        "        ##self.features14 = DepthWiseSeperable(1024, 1024, 1)\n",
        "\n",
        "\n",
        "        # Average pooling and classifier\n",
        "        self.avgpool = nn.AdaptiveAvgPool2d(1)\n",
        "        self.classifier = nn.Sequential(\n",
        "            nn.Linear(32, num_classes),\n",
        "        )\n",
        "\n",
        "    def forward(self, x):\n",
        "        x=  self.features1(x)\n",
        "        x = self.features2(x)\n",
        "        x = self.features3(x)\n",
        "        x = self.features4(x)\n",
        "        x = self.features5(x)\n",
        "        x = self.features6(x)\n",
        "        x = self.features7(x)\n",
        "        x = self.features8(x)\n",
        "        x = self.features9(x)\n",
        "        #x = self.features10(x)\n",
        "        #x = self.features11(x)\n",
        "        #x = self.features12(x)\n",
        "        #x = self.features13(x)\n",
        "        #x = self.features14(x)\n",
        "        x = self.avgpool(x)\n",
        "        x = x.view(x.size(0), -1)\n",
        "        x = self.classifier(x)\n",
        "        return x\n",
        "\n",
        "\n",
        "# Create an instance of MobileNetV1\n",
        "model = MobileNetV1()\n",
        "# print(model)\n",
        "\n",
        "\n",
        "def test_Mobilenet():\n",
        "    x = torch.randn(1,3,224,224)\n",
        "    model = MobileNetV1()\n",
        "    print(model(x).shape)\n",
        "\n",
        "    return model\n",
        "\n",
        "\n",
        "#model = test_Mobilenet()\n",
        "#architecture = 'mobilenetv1'\n",
        "#model_graph = draw_graph(model, input_size=(1,3,64,64), graph_dir ='TB' , roll=True, expand_nested=True, graph_name=f'self_{architecture}',save_graph=True,filename=f'self_{architecture}')\n",
        "# model_graph.visual_graph"
      ],
      "metadata": {
        "id": "2rACm1VKhQ86"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "test=img\n",
        "test.shape\n",
        "model_small=MobileNetV1_prunedblock6()\n",
        "test_input=test\n",
        "test_input.shape\n",
        "test_model=model_small(test_input)\n",
        "test_model.shape\n",
        "\n",
        "total_params = sum(p.numel() for p in model_small.parameters())\n",
        "print(\"Total number of parameters: \", total_params)"
      ],
      "metadata": {
        "id": "2uOl4p6BmkMg",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "25348f96-ffdf-4cbf-a8e5-490aa69a1ad9"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Total number of parameters:  310794\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install torchinfo\n",
        "from torchinfo import summary\n"
      ],
      "metadata": {
        "id": "ziRdhMvummfw",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "359fbe87-6463-4879-9cc5-0e085c7a1574"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting torchinfo\n",
            "  Downloading torchinfo-1.8.0-py3-none-any.whl (23 kB)\n",
            "Installing collected packages: torchinfo\n",
            "Successfully installed torchinfo-1.8.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Checking number of parameters of pruned network\n",
        "summary(model_small, input_size=(1, 3, 224, 224))"
      ],
      "metadata": {
        "id": "nKs9WfA3miMx",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ca6e0b40-ce7d-4c34-88e3-96085ffc4f01"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "==========================================================================================\n",
              "Layer (type:depth-idx)                   Output Shape              Param #\n",
              "==========================================================================================\n",
              "MobileNetV1_prunedblock6                 [1, 10]                   --\n",
              "├─Sequential: 1-1                        [1, 32, 112, 112]         --\n",
              "│    └─Conv2d: 2-1                       [1, 32, 112, 112]         864\n",
              "│    └─ReLU: 2-2                         [1, 32, 112, 112]         --\n",
              "│    └─BatchNorm2d: 2-3                  [1, 32, 112, 112]         64\n",
              "├─DepthWiseSeperable: 1-2                [1, 64, 112, 112]         --\n",
              "│    └─Conv2d: 2-4                       [1, 32, 112, 112]         288\n",
              "│    └─BatchNorm2d: 2-5                  [1, 32, 112, 112]         64\n",
              "│    └─ReLU: 2-6                         [1, 32, 112, 112]         --\n",
              "│    └─Conv2d: 2-7                       [1, 64, 112, 112]         2,048\n",
              "│    └─BatchNorm2d: 2-8                  [1, 64, 112, 112]         128\n",
              "│    └─ReLU: 2-9                         [1, 64, 112, 112]         --\n",
              "├─DepthWiseSeperable: 1-3                [1, 128, 56, 56]          --\n",
              "│    └─Conv2d: 2-10                      [1, 64, 56, 56]           576\n",
              "│    └─BatchNorm2d: 2-11                 [1, 64, 56, 56]           128\n",
              "│    └─ReLU: 2-12                        [1, 64, 56, 56]           --\n",
              "│    └─Conv2d: 2-13                      [1, 128, 56, 56]          8,192\n",
              "│    └─BatchNorm2d: 2-14                 [1, 128, 56, 56]          256\n",
              "│    └─ReLU: 2-15                        [1, 128, 56, 56]          --\n",
              "├─DepthWiseSeperable: 1-4                [1, 128, 56, 56]          --\n",
              "│    └─Conv2d: 2-16                      [1, 128, 56, 56]          1,152\n",
              "│    └─BatchNorm2d: 2-17                 [1, 128, 56, 56]          256\n",
              "│    └─ReLU: 2-18                        [1, 128, 56, 56]          --\n",
              "│    └─Conv2d: 2-19                      [1, 128, 56, 56]          16,384\n",
              "│    └─BatchNorm2d: 2-20                 [1, 128, 56, 56]          256\n",
              "│    └─ReLU: 2-21                        [1, 128, 56, 56]          --\n",
              "├─DepthWiseSeperable: 1-5                [1, 256, 28, 28]          --\n",
              "│    └─Conv2d: 2-22                      [1, 128, 28, 28]          1,152\n",
              "│    └─BatchNorm2d: 2-23                 [1, 128, 28, 28]          256\n",
              "│    └─ReLU: 2-24                        [1, 128, 28, 28]          --\n",
              "│    └─Conv2d: 2-25                      [1, 256, 28, 28]          32,768\n",
              "│    └─BatchNorm2d: 2-26                 [1, 256, 28, 28]          512\n",
              "│    └─ReLU: 2-27                        [1, 256, 28, 28]          --\n",
              "├─DepthWiseSeperable: 1-6                [1, 256, 28, 28]          --\n",
              "│    └─Conv2d: 2-28                      [1, 256, 28, 28]          2,304\n",
              "│    └─BatchNorm2d: 2-29                 [1, 256, 28, 28]          512\n",
              "│    └─ReLU: 2-30                        [1, 256, 28, 28]          --\n",
              "│    └─Conv2d: 2-31                      [1, 256, 28, 28]          65,536\n",
              "│    └─BatchNorm2d: 2-32                 [1, 256, 28, 28]          512\n",
              "│    └─ReLU: 2-33                        [1, 256, 28, 28]          --\n",
              "├─DepthWiseSeperable: 1-7                [1, 512, 14, 14]          --\n",
              "│    └─Conv2d: 2-34                      [1, 256, 14, 14]          2,304\n",
              "│    └─BatchNorm2d: 2-35                 [1, 256, 14, 14]          512\n",
              "│    └─ReLU: 2-36                        [1, 256, 14, 14]          --\n",
              "│    └─Conv2d: 2-37                      [1, 512, 14, 14]          131,072\n",
              "│    └─BatchNorm2d: 2-38                 [1, 512, 14, 14]          1,024\n",
              "│    └─ReLU: 2-39                        [1, 512, 14, 14]          --\n",
              "├─DepthWiseSeperable: 1-8                [1, 64, 14, 14]           --\n",
              "│    └─Conv2d: 2-40                      [1, 512, 14, 14]          4,608\n",
              "│    └─BatchNorm2d: 2-41                 [1, 512, 14, 14]          1,024\n",
              "│    └─ReLU: 2-42                        [1, 512, 14, 14]          --\n",
              "│    └─Conv2d: 2-43                      [1, 64, 14, 14]           32,768\n",
              "│    └─BatchNorm2d: 2-44                 [1, 64, 14, 14]           128\n",
              "│    └─ReLU: 2-45                        [1, 64, 14, 14]           --\n",
              "├─DepthWiseSeperable: 1-9                [1, 32, 14, 14]           --\n",
              "│    └─Conv2d: 2-46                      [1, 64, 14, 14]           576\n",
              "│    └─BatchNorm2d: 2-47                 [1, 64, 14, 14]           128\n",
              "│    └─ReLU: 2-48                        [1, 64, 14, 14]           --\n",
              "│    └─Conv2d: 2-49                      [1, 32, 14, 14]           2,048\n",
              "│    └─BatchNorm2d: 2-50                 [1, 32, 14, 14]           64\n",
              "│    └─ReLU: 2-51                        [1, 32, 14, 14]           --\n",
              "├─AdaptiveAvgPool2d: 1-10                [1, 32, 1, 1]             --\n",
              "├─Sequential: 1-11                       [1, 10]                   --\n",
              "│    └─Linear: 2-52                      [1, 10]                   330\n",
              "==========================================================================================\n",
              "Total params: 310,794\n",
              "Trainable params: 310,794\n",
              "Non-trainable params: 0\n",
              "Total mult-adds (M): 236.40\n",
              "==========================================================================================\n",
              "Input size (MB): 0.60\n",
              "Forward/backward pass size (MB): 63.92\n",
              "Params size (MB): 1.24\n",
              "Estimated Total Size (MB): 65.77\n",
              "=========================================================================================="
            ]
          },
          "metadata": {},
          "execution_count": 22
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Checking number of parameters of pruned network\n",
        "summary(model_big, input_size=(1, 3, 224, 224))"
      ],
      "metadata": {
        "id": "DfRkk3J3my3U",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "aa0c7420-a96a-430b-cbff-5b5a4ca7285c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "==========================================================================================\n",
              "Layer (type:depth-idx)                   Output Shape              Param #\n",
              "==========================================================================================\n",
              "MobileNetV1                              [1, 10]                   --\n",
              "├─Sequential: 1-1                        [1, 32, 112, 112]         --\n",
              "│    └─Conv2d: 2-1                       [1, 32, 112, 112]         864\n",
              "│    └─ReLU: 2-2                         [1, 32, 112, 112]         --\n",
              "│    └─BatchNorm2d: 2-3                  [1, 32, 112, 112]         64\n",
              "├─DepthWiseSeperable: 1-2                [1, 64, 112, 112]         --\n",
              "│    └─Conv2d: 2-4                       [1, 32, 112, 112]         288\n",
              "│    └─BatchNorm2d: 2-5                  [1, 32, 112, 112]         64\n",
              "│    └─ReLU: 2-6                         [1, 32, 112, 112]         --\n",
              "│    └─Conv2d: 2-7                       [1, 64, 112, 112]         2,048\n",
              "│    └─BatchNorm2d: 2-8                  [1, 64, 112, 112]         128\n",
              "│    └─ReLU: 2-9                         [1, 64, 112, 112]         --\n",
              "├─DepthWiseSeperable: 1-3                [1, 128, 56, 56]          --\n",
              "│    └─Conv2d: 2-10                      [1, 64, 56, 56]           576\n",
              "│    └─BatchNorm2d: 2-11                 [1, 64, 56, 56]           128\n",
              "│    └─ReLU: 2-12                        [1, 64, 56, 56]           --\n",
              "│    └─Conv2d: 2-13                      [1, 128, 56, 56]          8,192\n",
              "│    └─BatchNorm2d: 2-14                 [1, 128, 56, 56]          256\n",
              "│    └─ReLU: 2-15                        [1, 128, 56, 56]          --\n",
              "├─DepthWiseSeperable: 1-4                [1, 128, 56, 56]          --\n",
              "│    └─Conv2d: 2-16                      [1, 128, 56, 56]          1,152\n",
              "│    └─BatchNorm2d: 2-17                 [1, 128, 56, 56]          256\n",
              "│    └─ReLU: 2-18                        [1, 128, 56, 56]          --\n",
              "│    └─Conv2d: 2-19                      [1, 128, 56, 56]          16,384\n",
              "│    └─BatchNorm2d: 2-20                 [1, 128, 56, 56]          256\n",
              "│    └─ReLU: 2-21                        [1, 128, 56, 56]          --\n",
              "├─DepthWiseSeperable: 1-5                [1, 256, 28, 28]          --\n",
              "│    └─Conv2d: 2-22                      [1, 128, 28, 28]          1,152\n",
              "│    └─BatchNorm2d: 2-23                 [1, 128, 28, 28]          256\n",
              "│    └─ReLU: 2-24                        [1, 128, 28, 28]          --\n",
              "│    └─Conv2d: 2-25                      [1, 256, 28, 28]          32,768\n",
              "│    └─BatchNorm2d: 2-26                 [1, 256, 28, 28]          512\n",
              "│    └─ReLU: 2-27                        [1, 256, 28, 28]          --\n",
              "├─DepthWiseSeperable: 1-6                [1, 256, 28, 28]          --\n",
              "│    └─Conv2d: 2-28                      [1, 256, 28, 28]          2,304\n",
              "│    └─BatchNorm2d: 2-29                 [1, 256, 28, 28]          512\n",
              "│    └─ReLU: 2-30                        [1, 256, 28, 28]          --\n",
              "│    └─Conv2d: 2-31                      [1, 256, 28, 28]          65,536\n",
              "│    └─BatchNorm2d: 2-32                 [1, 256, 28, 28]          512\n",
              "│    └─ReLU: 2-33                        [1, 256, 28, 28]          --\n",
              "├─DepthWiseSeperable: 1-7                [1, 512, 14, 14]          --\n",
              "│    └─Conv2d: 2-34                      [1, 256, 14, 14]          2,304\n",
              "│    └─BatchNorm2d: 2-35                 [1, 256, 14, 14]          512\n",
              "│    └─ReLU: 2-36                        [1, 256, 14, 14]          --\n",
              "│    └─Conv2d: 2-37                      [1, 512, 14, 14]          131,072\n",
              "│    └─BatchNorm2d: 2-38                 [1, 512, 14, 14]          1,024\n",
              "│    └─ReLU: 2-39                        [1, 512, 14, 14]          --\n",
              "├─DepthWiseSeperable: 1-8                [1, 512, 14, 14]          --\n",
              "│    └─Conv2d: 2-40                      [1, 512, 14, 14]          4,608\n",
              "│    └─BatchNorm2d: 2-41                 [1, 512, 14, 14]          1,024\n",
              "│    └─ReLU: 2-42                        [1, 512, 14, 14]          --\n",
              "│    └─Conv2d: 2-43                      [1, 512, 14, 14]          262,144\n",
              "│    └─BatchNorm2d: 2-44                 [1, 512, 14, 14]          1,024\n",
              "│    └─ReLU: 2-45                        [1, 512, 14, 14]          --\n",
              "├─DepthWiseSeperable: 1-9                [1, 512, 14, 14]          --\n",
              "│    └─Conv2d: 2-46                      [1, 512, 14, 14]          4,608\n",
              "│    └─BatchNorm2d: 2-47                 [1, 512, 14, 14]          1,024\n",
              "│    └─ReLU: 2-48                        [1, 512, 14, 14]          --\n",
              "│    └─Conv2d: 2-49                      [1, 512, 14, 14]          262,144\n",
              "│    └─BatchNorm2d: 2-50                 [1, 512, 14, 14]          1,024\n",
              "│    └─ReLU: 2-51                        [1, 512, 14, 14]          --\n",
              "├─DepthWiseSeperable: 1-10               [1, 512, 14, 14]          --\n",
              "│    └─Conv2d: 2-52                      [1, 512, 14, 14]          4,608\n",
              "│    └─BatchNorm2d: 2-53                 [1, 512, 14, 14]          1,024\n",
              "│    └─ReLU: 2-54                        [1, 512, 14, 14]          --\n",
              "│    └─Conv2d: 2-55                      [1, 512, 14, 14]          262,144\n",
              "│    └─BatchNorm2d: 2-56                 [1, 512, 14, 14]          1,024\n",
              "│    └─ReLU: 2-57                        [1, 512, 14, 14]          --\n",
              "├─DepthWiseSeperable: 1-11               [1, 512, 14, 14]          --\n",
              "│    └─Conv2d: 2-58                      [1, 512, 14, 14]          4,608\n",
              "│    └─BatchNorm2d: 2-59                 [1, 512, 14, 14]          1,024\n",
              "│    └─ReLU: 2-60                        [1, 512, 14, 14]          --\n",
              "│    └─Conv2d: 2-61                      [1, 512, 14, 14]          262,144\n",
              "│    └─BatchNorm2d: 2-62                 [1, 512, 14, 14]          1,024\n",
              "│    └─ReLU: 2-63                        [1, 512, 14, 14]          --\n",
              "├─DepthWiseSeperable: 1-12               [1, 512, 14, 14]          --\n",
              "│    └─Conv2d: 2-64                      [1, 512, 14, 14]          4,608\n",
              "│    └─BatchNorm2d: 2-65                 [1, 512, 14, 14]          1,024\n",
              "│    └─ReLU: 2-66                        [1, 512, 14, 14]          --\n",
              "│    └─Conv2d: 2-67                      [1, 512, 14, 14]          262,144\n",
              "│    └─BatchNorm2d: 2-68                 [1, 512, 14, 14]          1,024\n",
              "│    └─ReLU: 2-69                        [1, 512, 14, 14]          --\n",
              "├─DepthWiseSeperable: 1-13               [1, 1024, 7, 7]           --\n",
              "│    └─Conv2d: 2-70                      [1, 512, 7, 7]            4,608\n",
              "│    └─BatchNorm2d: 2-71                 [1, 512, 7, 7]            1,024\n",
              "│    └─ReLU: 2-72                        [1, 512, 7, 7]            --\n",
              "│    └─Conv2d: 2-73                      [1, 1024, 7, 7]           524,288\n",
              "│    └─BatchNorm2d: 2-74                 [1, 1024, 7, 7]           2,048\n",
              "│    └─ReLU: 2-75                        [1, 1024, 7, 7]           --\n",
              "├─DepthWiseSeperable: 1-14               [1, 1024, 7, 7]           --\n",
              "│    └─Conv2d: 2-76                      [1, 1024, 7, 7]           9,216\n",
              "│    └─BatchNorm2d: 2-77                 [1, 1024, 7, 7]           2,048\n",
              "│    └─ReLU: 2-78                        [1, 1024, 7, 7]           --\n",
              "│    └─Conv2d: 2-79                      [1, 1024, 7, 7]           1,048,576\n",
              "│    └─BatchNorm2d: 2-80                 [1, 1024, 7, 7]           2,048\n",
              "│    └─ReLU: 2-81                        [1, 1024, 7, 7]           --\n",
              "├─AdaptiveAvgPool2d: 1-15                [1, 1024, 1, 1]           --\n",
              "├─Sequential: 1-16                       [1, 10]                   --\n",
              "│    └─Linear: 2-82                      [1, 10]                   10,250\n",
              "==========================================================================================\n",
              "Total params: 3,217,226\n",
              "Trainable params: 3,217,226\n",
              "Non-trainable params: 0\n",
              "Total mult-adds (M): 567.75\n",
              "==========================================================================================\n",
              "Input size (MB): 0.60\n",
              "Forward/backward pass size (MB): 80.68\n",
              "Params size (MB): 12.87\n",
              "Estimated Total Size (MB): 94.15\n",
              "=========================================================================================="
            ]
          },
          "metadata": {},
          "execution_count": 23
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Pruned Network only have ~310k parameters while the original network have 3.2M parameters. Step below copies the weights of the original network on the Pruned Network"
      ],
      "metadata": {
        "id": "xgxD6o69uhKW"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "#Copying weights\n",
        "model_small=MobileNetV1_prunedblock6()\n",
        "\n",
        "features1_parameters = model_big.features1.state_dict()\n",
        "features2_parameters = model_big.features2.state_dict()\n",
        "features3_parameters = model_big.features3.state_dict()\n",
        "features4_parameters = model_big.features4.state_dict()\n",
        "features5_parameters = model_big.features5.state_dict()\n",
        "features6_parameters = model_big.features6.state_dict()\n",
        "features7_parameters = model_big.features7.state_dict()\n",
        "\n",
        "\n",
        "model_small.features1.load_state_dict(features1_parameters)\n",
        "model_small.features2.load_state_dict(features2_parameters)\n",
        "model_small.features3.load_state_dict(features3_parameters)\n",
        "model_small.features4.load_state_dict(features4_parameters)\n",
        "model_small.features5.load_state_dict(features5_parameters)\n",
        "model_small.features6.load_state_dict(features6_parameters)\n",
        "model_small.features7.load_state_dict(features7_parameters)\n",
        "for param in model_small.features1.parameters():\n",
        "    param.requires_grad = True\n",
        "\n",
        "for param in model_small.features2.parameters():\n",
        "    param.requires_grad = True\n",
        "\n",
        "\n",
        "loss_fn=nn.CrossEntropyLoss()#Loss Function\n",
        "\n",
        "\n",
        "optimizer1=torch.optim.Adam(params=model_small.parameters(),lr=0.0005,weight_decay=0.001) #Optimizer\n",
        "\n",
        "\n",
        "lr_scheduler = CosineAnnealingLR(optimizer1, T_max=500)"
      ],
      "metadata": {
        "id": "XGi4OfDZm1rN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Checking if parameter copy is successful\n",
        "model_big.features2.state_dict()"
      ],
      "metadata": {
        "id": "BUYgnZZusDix",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "12fba054-87e1-4f45-d173-892375cf51b3"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "OrderedDict([('depthwise.weight',\n",
              "              tensor([[[[ 8.3048e-02, -2.4413e-01, -1.6181e-01],\n",
              "                        [ 4.6391e-02, -5.8634e-03,  4.4460e-02],\n",
              "                        [-1.7339e-02,  2.0203e-01,  2.4437e-01]]],\n",
              "              \n",
              "              \n",
              "                      [[[ 9.2187e-02,  1.4106e-01, -1.6692e-02],\n",
              "                        [ 1.3193e-01,  1.8768e-01, -9.0031e-02],\n",
              "                        [-5.9208e-02, -5.4091e-02, -1.5911e-01]]],\n",
              "              \n",
              "              \n",
              "                      [[[-5.5917e-02,  1.4010e-01,  1.7752e-01],\n",
              "                        [ 4.4780e-02, -9.5942e-02, -1.0269e-01],\n",
              "                        [-4.9953e-02, -1.4805e-01, -8.2106e-02]]],\n",
              "              \n",
              "              \n",
              "                      [[[-6.2818e-02, -2.1594e-02,  8.0734e-02],\n",
              "                        [-1.2458e-01,  6.2378e-02,  9.6277e-02],\n",
              "                        [-1.1928e-01,  7.0790e-02,  5.8373e-02]]],\n",
              "              \n",
              "              \n",
              "                      [[[ 8.7017e-02,  6.1055e-02,  1.2944e-01],\n",
              "                        [-2.1255e-02,  2.4452e-01,  7.3095e-02],\n",
              "                        [-2.5980e-01,  9.2303e-02, -2.4311e-01]]],\n",
              "              \n",
              "              \n",
              "                      [[[-1.9478e-01,  1.4801e-01,  2.6778e-01],\n",
              "                        [-9.5895e-02, -1.4578e-01,  1.1449e-01],\n",
              "                        [-1.6376e-02,  1.8981e-01, -1.0339e-01]]],\n",
              "              \n",
              "              \n",
              "                      [[[ 9.6548e-02, -2.4979e-01, -7.1727e-02],\n",
              "                        [-8.4912e-02,  1.1208e-01,  1.0247e-01],\n",
              "                        [-1.7261e-01,  3.0489e-01,  6.8834e-02]]],\n",
              "              \n",
              "              \n",
              "                      [[[ 3.3603e-02, -1.6872e-01,  2.0944e-01],\n",
              "                        [-1.7523e-01,  1.2940e-01,  5.0229e-02],\n",
              "                        [-2.1213e-01, -1.6581e-01,  1.6641e-01]]],\n",
              "              \n",
              "              \n",
              "                      [[[ 4.9548e-02, -1.8262e-01,  5.8393e-02],\n",
              "                        [ 4.7330e-02, -3.6624e-02, -8.9739e-02],\n",
              "                        [ 1.9196e-01,  2.4803e-01,  4.3971e-03]]],\n",
              "              \n",
              "              \n",
              "                      [[[ 1.4728e-02, -3.6978e-02,  1.7471e-02],\n",
              "                        [ 4.7291e-02, -6.7506e-02, -4.3630e-02],\n",
              "                        [ 4.9350e-02, -5.2754e-02, -7.4760e-02]]],\n",
              "              \n",
              "              \n",
              "                      [[[-7.3556e-02, -1.8478e-02, -2.8321e-02],\n",
              "                        [-9.3034e-02,  1.6111e-01,  5.8814e-02],\n",
              "                        [ 4.1328e-02,  1.2097e-01,  5.2034e-02]]],\n",
              "              \n",
              "              \n",
              "                      [[[-1.3074e-01,  2.7769e-02,  3.6381e-02],\n",
              "                        [-2.9957e-02,  9.0624e-02,  1.1598e-01],\n",
              "                        [ 9.8655e-02, -1.8301e-02,  7.5554e-02]]],\n",
              "              \n",
              "              \n",
              "                      [[[-1.0062e-02,  3.5400e-02,  4.3648e-02],\n",
              "                        [-1.2679e-02,  2.2702e-02,  3.3102e-02],\n",
              "                        [ 1.0974e-02,  3.5623e-02,  2.7528e-02]]],\n",
              "              \n",
              "              \n",
              "                      [[[-2.6186e-01, -3.5365e-02, -2.6771e-02],\n",
              "                        [-2.0765e-01,  2.4714e-01,  1.6182e-01],\n",
              "                        [-3.5040e-04,  1.1449e-01,  1.4070e-01]]],\n",
              "              \n",
              "              \n",
              "                      [[[ 1.0750e-02,  1.3882e-01,  3.9747e-02],\n",
              "                        [ 1.6921e-01, -6.9366e-02,  1.6083e-01],\n",
              "                        [-2.9142e-02, -1.7493e-01, -1.2558e-01]]],\n",
              "              \n",
              "              \n",
              "                      [[[-1.1921e-01,  1.4359e-01, -2.5720e-01],\n",
              "                        [-1.7645e-02,  7.3361e-02,  1.5230e-01],\n",
              "                        [ 3.5273e-02,  6.6097e-02,  9.9429e-02]]],\n",
              "              \n",
              "              \n",
              "                      [[[-8.8923e-02,  2.4698e-01,  4.5659e-02],\n",
              "                        [ 2.4238e-01, -5.4864e-02,  1.7007e-01],\n",
              "                        [-2.7261e-01, -5.9969e-03, -2.5140e-01]]],\n",
              "              \n",
              "              \n",
              "                      [[[ 1.1788e-01,  1.5416e-04,  5.8157e-02],\n",
              "                        [-6.0608e-02, -8.6205e-02,  3.2300e-02],\n",
              "                        [-4.3374e-02, -7.7653e-02, -6.0328e-02]]],\n",
              "              \n",
              "              \n",
              "                      [[[ 7.9670e-02,  1.4435e-01,  1.1779e-01],\n",
              "                        [ 6.3570e-02,  1.8778e-01,  6.5323e-02],\n",
              "                        [-1.9092e-01, -1.6685e-01, -4.0897e-02]]],\n",
              "              \n",
              "              \n",
              "                      [[[-1.9134e-02,  7.8752e-03, -1.6155e-01],\n",
              "                        [-8.8185e-03,  1.5030e-01,  2.2047e-01],\n",
              "                        [-2.2918e-01,  3.8409e-02,  8.0433e-02]]],\n",
              "              \n",
              "              \n",
              "                      [[[-1.2027e-01,  1.1385e-01, -9.8482e-02],\n",
              "                        [ 1.1165e-01,  9.5113e-02,  4.4890e-02],\n",
              "                        [ 1.0607e-01,  5.3086e-02, -1.2323e-01]]],\n",
              "              \n",
              "              \n",
              "                      [[[-1.4984e-01, -1.3375e-01,  2.3141e-01],\n",
              "                        [ 1.5365e-02, -3.9753e-02,  3.0032e-01],\n",
              "                        [-2.0651e-01,  2.2799e-02,  1.6475e-01]]],\n",
              "              \n",
              "              \n",
              "                      [[[-1.9487e-01, -2.4101e-02, -1.6514e-02],\n",
              "                        [ 1.6762e-01, -6.3128e-02, -6.7829e-03],\n",
              "                        [-3.6973e-02,  3.0091e-01,  7.7144e-02]]],\n",
              "              \n",
              "              \n",
              "                      [[[ 4.9045e-42, -4.9536e-42,  4.9410e-42],\n",
              "                        [ 4.9059e-42, -4.9354e-42,  4.9144e-42],\n",
              "                        [-4.9200e-42, -4.9214e-42, -4.9158e-42]]],\n",
              "              \n",
              "              \n",
              "                      [[[ 5.6912e-02, -1.0019e-01,  7.7250e-02],\n",
              "                        [ 1.4353e-01,  6.9944e-03,  6.9320e-02],\n",
              "                        [-1.1423e-01, -1.6329e-01, -1.1192e-01]]],\n",
              "              \n",
              "              \n",
              "                      [[[-5.9258e-02,  1.9249e-02, -5.9093e-02],\n",
              "                        [ 3.8310e-02,  1.1408e-01,  5.8449e-02],\n",
              "                        [-3.5383e-02,  4.5068e-02,  9.9167e-02]]],\n",
              "              \n",
              "              \n",
              "                      [[[ 1.9093e-02, -2.2940e-03,  7.9662e-02],\n",
              "                        [-9.0408e-03, -1.9226e-02,  7.0109e-03],\n",
              "                        [ 2.8351e-03, -1.3032e-02, -1.0884e-02]]],\n",
              "              \n",
              "              \n",
              "                      [[[ 1.0631e-01, -1.9595e-01, -2.2940e-01],\n",
              "                        [-3.7517e-02,  1.6763e-01,  4.9996e-03],\n",
              "                        [ 1.9316e-01, -4.1548e-02, -1.0528e-01]]],\n",
              "              \n",
              "              \n",
              "                      [[[ 7.7039e-02,  2.5585e-01, -1.5821e-01],\n",
              "                        [-2.7285e-01,  1.8698e-01,  3.1946e-01],\n",
              "                        [-2.0149e-01, -1.2655e-01, -1.4981e-02]]],\n",
              "              \n",
              "              \n",
              "                      [[[ 6.1063e-02, -3.9502e-02,  1.1194e-01],\n",
              "                        [-3.6262e-02,  5.8025e-02, -1.3486e-01],\n",
              "                        [ 2.7448e-01, -1.3710e-01, -1.3340e-01]]],\n",
              "              \n",
              "              \n",
              "                      [[[-2.4266e-01,  1.6134e-01, -2.6085e-01],\n",
              "                        [ 8.1489e-02,  1.9834e-01,  2.9592e-01],\n",
              "                        [-7.9506e-02, -1.8915e-01,  1.4630e-01]]],\n",
              "              \n",
              "              \n",
              "                      [[[-1.0318e-01, -1.4924e-02,  7.6484e-03],\n",
              "                        [ 7.6733e-02,  6.6449e-02, -1.1107e-01],\n",
              "                        [ 1.4035e-01,  1.4835e-01,  7.7258e-02]]]], device='cuda:0')),\n",
              "             ('bn1.weight',\n",
              "              tensor([4.0673e-01, 1.9111e-01, 2.9307e-01, 3.0390e-01, 4.0976e-01, 4.1857e-01,\n",
              "                      3.0405e-01, 2.9885e-01, 3.3411e-01, 1.3068e-01, 3.9202e-01, 2.4710e-01,\n",
              "                      1.7422e-01, 3.3836e-01, 1.4489e-01, 4.5885e-01, 3.0631e-01, 1.6021e-01,\n",
              "                      3.8278e-01, 2.4618e-01, 3.2062e-01, 4.2978e-01, 3.4803e-01, 4.9522e-42,\n",
              "                      2.1571e-01, 3.6002e-01, 1.1254e-01, 2.7195e-01, 3.1958e-01, 2.4340e-01,\n",
              "                      2.7052e-01, 4.6022e-01], device='cuda:0')),\n",
              "             ('bn1.bias',\n",
              "              tensor([ 3.3594e-01,  2.4711e-02,  4.8811e-02,  2.2627e-01,  1.3064e-01,\n",
              "                       2.2677e-01,  2.8439e-01,  1.0991e-01,  1.7576e-01, -2.8584e-02,\n",
              "                       2.1369e-01,  1.9631e-01,  1.3377e-03,  2.8795e-01, -3.3045e-02,\n",
              "                       1.4036e-01,  2.5934e-01, -2.1233e-02,  2.9543e-01,  1.9018e-01,\n",
              "                       7.1208e-02,  1.1806e-01,  3.1985e-01,  4.9424e-42,  9.3101e-03,\n",
              "                       2.4394e-01,  1.1489e-01, -9.0482e-03,  2.9150e-02,  4.8520e-02,\n",
              "                       1.2693e-01,  2.3515e-01], device='cuda:0')),\n",
              "             ('bn1.running_mean',\n",
              "              tensor([ 1.0591e-02, -3.9995e-03, -9.6174e-03,  2.4860e-03, -1.2277e-02,\n",
              "                      -1.1879e-03,  9.0022e-04, -1.5673e-03,  1.0927e-02, -5.9406e-03,\n",
              "                       9.2831e-03,  8.9837e-03, -6.7239e-04,  5.2345e-03, -6.7574e-03,\n",
              "                       5.0755e-03, -3.2649e-03, -7.5917e-04,  7.6730e-03, -5.4731e-03,\n",
              "                       1.2871e-02,  9.2063e-03, -9.1589e-03, -5.6052e-45,  5.0950e-03,\n",
              "                       5.2249e-03,  1.7963e-03, -6.8108e-04, -1.1433e-04,  9.4384e-04,\n",
              "                       5.1874e-03,  1.6187e-02], device='cuda:0')),\n",
              "             ('bn1.running_var',\n",
              "              tensor([1.9827e-04, 1.0966e-04, 8.0784e-05, 2.9006e-05, 1.7295e-04, 1.7927e-04,\n",
              "                      9.0124e-05, 8.2558e-05, 1.3388e-04, 4.2438e-05, 2.2022e-04, 2.6187e-04,\n",
              "                      3.9436e-05, 1.4983e-04, 4.5630e-05, 1.3741e-04, 6.1618e-05, 4.4633e-05,\n",
              "                      4.1850e-04, 6.5116e-05, 1.4005e-04, 2.8341e-04, 1.8157e-04, 5.6052e-45,\n",
              "                      4.4872e-05, 2.5497e-04, 5.3983e-07, 8.2851e-05, 8.5681e-05, 1.0487e-05,\n",
              "                      4.2521e-05, 1.7783e-04], device='cuda:0')),\n",
              "             ('bn1.num_batches_tracked', tensor(38318, device='cuda:0')),\n",
              "             ('pointwise.weight',\n",
              "              tensor([[[[ 4.9200e-42]],\n",
              "              \n",
              "                       [[ 4.9186e-42]],\n",
              "              \n",
              "                       [[ 4.9059e-42]],\n",
              "              \n",
              "                       ...,\n",
              "              \n",
              "                       [[ 4.9200e-42]],\n",
              "              \n",
              "                       [[-4.9101e-42]],\n",
              "              \n",
              "                       [[-4.9522e-42]]],\n",
              "              \n",
              "              \n",
              "                      [[[ 5.6090e-05]],\n",
              "              \n",
              "                       [[ 2.5665e-02]],\n",
              "              \n",
              "                       [[-6.3165e-03]],\n",
              "              \n",
              "                       ...,\n",
              "              \n",
              "                       [[-4.8513e-02]],\n",
              "              \n",
              "                       [[-2.4009e-02]],\n",
              "              \n",
              "                       [[-9.1119e-02]]],\n",
              "              \n",
              "              \n",
              "                      [[[ 1.2307e-01]],\n",
              "              \n",
              "                       [[ 1.7690e-02]],\n",
              "              \n",
              "                       [[ 9.4334e-02]],\n",
              "              \n",
              "                       ...,\n",
              "              \n",
              "                       [[ 1.3215e-01]],\n",
              "              \n",
              "                       [[ 7.1982e-02]],\n",
              "              \n",
              "                       [[-1.8819e-02]]],\n",
              "              \n",
              "              \n",
              "                      ...,\n",
              "              \n",
              "              \n",
              "                      [[[ 5.5964e-03]],\n",
              "              \n",
              "                       [[ 3.7447e-03]],\n",
              "              \n",
              "                       [[-1.7150e-03]],\n",
              "              \n",
              "                       ...,\n",
              "              \n",
              "                       [[-1.2496e-04]],\n",
              "              \n",
              "                       [[ 3.6106e-04]],\n",
              "              \n",
              "                       [[ 4.1540e-02]]],\n",
              "              \n",
              "              \n",
              "                      [[[-1.1291e-01]],\n",
              "              \n",
              "                       [[-4.3837e-02]],\n",
              "              \n",
              "                       [[ 7.6924e-02]],\n",
              "              \n",
              "                       ...,\n",
              "              \n",
              "                       [[-7.3967e-03]],\n",
              "              \n",
              "                       [[-3.6342e-02]],\n",
              "              \n",
              "                       [[-5.8924e-02]]],\n",
              "              \n",
              "              \n",
              "                      [[[ 2.2143e-04]],\n",
              "              \n",
              "                       [[-1.3727e-04]],\n",
              "              \n",
              "                       [[ 7.3298e-08]],\n",
              "              \n",
              "                       ...,\n",
              "              \n",
              "                       [[ 3.1315e-07]],\n",
              "              \n",
              "                       [[-9.5159e-05]],\n",
              "              \n",
              "                       [[ 1.1914e-03]]]], device='cuda:0')),\n",
              "             ('bn2.weight',\n",
              "              tensor([4.9256e-42, 4.7985e-02, 6.1030e-02, 9.8693e-02, 4.9410e-42, 4.9522e-42,\n",
              "                      3.3179e-28, 3.3398e-02, 4.9522e-42, 4.9200e-42, 4.6379e-02, 6.9142e-02,\n",
              "                      4.9062e-02, 8.3008e-02, 4.9087e-42, 7.3530e-02, 1.6275e-02, 7.8716e-02,\n",
              "                      5.1020e-02, 5.3519e-02, 5.5909e-02, 4.9312e-42, 1.2378e-01, 7.3358e-02,\n",
              "                      4.9382e-42, 8.7591e-02, 4.9172e-42, 1.8903e-02, 3.5933e-02, 6.6732e-02,\n",
              "                      6.7696e-02, 1.8158e-08, 6.4190e-02, 1.4851e-04, 3.5237e-02, 4.9158e-42,\n",
              "                      1.0482e-01, 3.8599e-02, 4.5826e-02, 4.4756e-02, 4.7904e-02, 4.4057e-02,\n",
              "                      6.8423e-02, 6.4260e-02, 4.9200e-42, 8.8088e-02, 3.5753e-02, 6.9179e-02,\n",
              "                      3.8335e-03, 7.7565e-02, 6.7915e-02, 3.0680e-02, 5.3501e-02, 4.6153e-02,\n",
              "                      8.9292e-02, 5.6884e-02, 4.1579e-02, 7.4350e-02, 1.2670e-02, 6.4245e-02,\n",
              "                      4.9200e-42, 4.1917e-02, 8.8920e-02, 2.9236e-03], device='cuda:0')),\n",
              "             ('bn2.bias',\n",
              "              tensor([ 4.9354e-42,  5.4023e-02,  1.0941e-01,  1.7925e-02, -4.9480e-42,\n",
              "                      -4.9200e-42,  1.4782e-10,  8.3804e-02,  4.9059e-42, -4.9059e-42,\n",
              "                       9.4027e-02,  5.7602e-02,  8.3493e-02,  6.1893e-02,  4.9438e-42,\n",
              "                       4.9660e-02,  3.8911e-02,  1.2284e-02,  6.3870e-02,  1.4668e-01,\n",
              "                       8.7511e-02, -4.9144e-42, -1.5068e-02,  8.2922e-02,  2.5822e-23,\n",
              "                       4.3883e-02,  4.9298e-42, -7.0259e-03,  4.2560e-02,  8.2802e-02,\n",
              "                       4.9672e-02,  2.3371e-08,  1.1012e-01,  2.5317e-11,  7.4552e-02,\n",
              "                       4.9340e-42,  7.5298e-03,  7.8701e-02,  8.5388e-02,  7.3068e-02,\n",
              "                       1.1208e-01,  8.9984e-02, -6.7004e-02,  4.4012e-02, -4.9228e-42,\n",
              "                      -2.3514e-02,  7.8501e-02,  1.6094e-02, -4.4116e-03,  6.5654e-02,\n",
              "                       1.3915e-01, -3.3941e-02,  1.0897e-01,  1.2369e-01,  7.7875e-02,\n",
              "                       1.1256e-01,  1.2118e-01,  5.2612e-02,  4.0328e-02,  6.9288e-02,\n",
              "                      -4.9298e-42, -1.1102e-01,  4.7455e-02,  3.8886e-06], device='cuda:0')),\n",
              "             ('bn2.running_mean',\n",
              "              tensor([ 5.6052e-45,  5.6348e-03,  7.3260e-03,  1.0535e-01, -2.0781e-42,\n",
              "                      -2.8082e-42,  2.7021e-19, -2.9937e-02,  5.6052e-45, -5.6052e-45,\n",
              "                       2.4916e-02,  8.1464e-02, -8.7154e-02, -3.2996e-02,  5.6052e-45,\n",
              "                       1.0404e-01, -5.1506e-02, -1.0624e-02, -1.3187e-02,  8.1209e-02,\n",
              "                       4.6488e-03, -8.8562e-43,  1.7718e-01,  4.8737e-02, -2.0781e-42,\n",
              "                      -6.7778e-03, -5.6052e-45,  3.9260e-02,  3.4590e-03, -6.5670e-02,\n",
              "                       1.1005e-02, -2.3022e-12,  4.5531e-02,  1.4664e-08, -5.0567e-02,\n",
              "                       5.6052e-45,  1.1145e-01, -2.7627e-02,  2.3821e-02,  3.1503e-02,\n",
              "                      -2.1405e-02, -3.7276e-02,  2.1192e-01,  3.3316e-02,  1.6115e-42,\n",
              "                       9.0072e-02,  3.1163e-02, -1.5918e-02,  6.2771e-04, -4.5743e-04,\n",
              "                       1.2678e-01,  4.8683e-02, -3.8880e-02, -7.1951e-02,  1.1759e-01,\n",
              "                       3.5971e-02, -7.8900e-02, -1.2320e-02, -6.4386e-03,  5.7013e-03,\n",
              "                      -5.6052e-45,  4.0606e-02, -5.0342e-02,  3.8165e-03], device='cuda:0')),\n",
              "             ('bn2.running_var',\n",
              "              tensor([5.6052e-45, 1.1812e-02, 2.3577e-02, 2.9855e-02, 5.6052e-45, 5.6052e-45,\n",
              "                      9.8952e-38, 1.3828e-02, 5.6052e-45, 5.6052e-45, 2.6124e-02, 1.7384e-02,\n",
              "                      8.4921e-03, 2.2026e-02, 5.6052e-45, 1.0232e-02, 2.0030e-03, 7.5810e-03,\n",
              "                      7.8857e-03, 1.4078e-02, 1.8456e-02, 5.6052e-45, 3.8170e-02, 2.9868e-02,\n",
              "                      5.6052e-45, 1.4786e-02, 5.6052e-45, 6.0365e-04, 2.6388e-03, 2.9288e-02,\n",
              "                      1.1948e-02, 3.8279e-23, 2.0596e-02, 4.2631e-16, 6.6297e-03, 5.6052e-45,\n",
              "                      2.6921e-02, 9.1171e-03, 9.3601e-03, 1.4562e-02, 1.0275e-02, 1.7951e-02,\n",
              "                      1.9699e-02, 5.4355e-03, 5.6052e-45, 1.2526e-02, 7.6567e-03, 5.2355e-03,\n",
              "                      5.4173e-07, 2.5943e-02, 5.0298e-02, 2.9451e-03, 1.2412e-02, 1.4281e-02,\n",
              "                      2.6444e-02, 2.0331e-02, 7.6887e-03, 6.5785e-03, 2.1663e-03, 1.0668e-02,\n",
              "                      5.6052e-45, 1.4106e-03, 1.6538e-02, 8.8833e-06], device='cuda:0')),\n",
              "             ('bn2.num_batches_tracked', tensor(38318, device='cuda:0'))])"
            ]
          },
          "metadata": {},
          "execution_count": 25
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Checking if parameter copy is successful\n",
        "model_small.features2.state_dict()"
      ],
      "metadata": {
        "id": "8Cf2mtnCsFIU",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ec868056-7cbb-49fd-a4ef-710eb50a1d1c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "OrderedDict([('depthwise.weight',\n",
              "              tensor([[[[ 8.3048e-02, -2.4413e-01, -1.6181e-01],\n",
              "                        [ 4.6391e-02, -5.8634e-03,  4.4460e-02],\n",
              "                        [-1.7339e-02,  2.0203e-01,  2.4437e-01]]],\n",
              "              \n",
              "              \n",
              "                      [[[ 9.2187e-02,  1.4106e-01, -1.6692e-02],\n",
              "                        [ 1.3193e-01,  1.8768e-01, -9.0031e-02],\n",
              "                        [-5.9208e-02, -5.4091e-02, -1.5911e-01]]],\n",
              "              \n",
              "              \n",
              "                      [[[-5.5917e-02,  1.4010e-01,  1.7752e-01],\n",
              "                        [ 4.4780e-02, -9.5942e-02, -1.0269e-01],\n",
              "                        [-4.9953e-02, -1.4805e-01, -8.2106e-02]]],\n",
              "              \n",
              "              \n",
              "                      [[[-6.2818e-02, -2.1594e-02,  8.0734e-02],\n",
              "                        [-1.2458e-01,  6.2378e-02,  9.6277e-02],\n",
              "                        [-1.1928e-01,  7.0790e-02,  5.8373e-02]]],\n",
              "              \n",
              "              \n",
              "                      [[[ 8.7017e-02,  6.1055e-02,  1.2944e-01],\n",
              "                        [-2.1255e-02,  2.4452e-01,  7.3095e-02],\n",
              "                        [-2.5980e-01,  9.2303e-02, -2.4311e-01]]],\n",
              "              \n",
              "              \n",
              "                      [[[-1.9478e-01,  1.4801e-01,  2.6778e-01],\n",
              "                        [-9.5895e-02, -1.4578e-01,  1.1449e-01],\n",
              "                        [-1.6376e-02,  1.8981e-01, -1.0339e-01]]],\n",
              "              \n",
              "              \n",
              "                      [[[ 9.6548e-02, -2.4979e-01, -7.1727e-02],\n",
              "                        [-8.4912e-02,  1.1208e-01,  1.0247e-01],\n",
              "                        [-1.7261e-01,  3.0489e-01,  6.8834e-02]]],\n",
              "              \n",
              "              \n",
              "                      [[[ 3.3603e-02, -1.6872e-01,  2.0944e-01],\n",
              "                        [-1.7523e-01,  1.2940e-01,  5.0229e-02],\n",
              "                        [-2.1213e-01, -1.6581e-01,  1.6641e-01]]],\n",
              "              \n",
              "              \n",
              "                      [[[ 4.9548e-02, -1.8262e-01,  5.8393e-02],\n",
              "                        [ 4.7330e-02, -3.6624e-02, -8.9739e-02],\n",
              "                        [ 1.9196e-01,  2.4803e-01,  4.3971e-03]]],\n",
              "              \n",
              "              \n",
              "                      [[[ 1.4728e-02, -3.6978e-02,  1.7471e-02],\n",
              "                        [ 4.7291e-02, -6.7506e-02, -4.3630e-02],\n",
              "                        [ 4.9350e-02, -5.2754e-02, -7.4760e-02]]],\n",
              "              \n",
              "              \n",
              "                      [[[-7.3556e-02, -1.8478e-02, -2.8321e-02],\n",
              "                        [-9.3034e-02,  1.6111e-01,  5.8814e-02],\n",
              "                        [ 4.1328e-02,  1.2097e-01,  5.2034e-02]]],\n",
              "              \n",
              "              \n",
              "                      [[[-1.3074e-01,  2.7769e-02,  3.6381e-02],\n",
              "                        [-2.9957e-02,  9.0624e-02,  1.1598e-01],\n",
              "                        [ 9.8655e-02, -1.8301e-02,  7.5554e-02]]],\n",
              "              \n",
              "              \n",
              "                      [[[-1.0062e-02,  3.5400e-02,  4.3648e-02],\n",
              "                        [-1.2679e-02,  2.2702e-02,  3.3102e-02],\n",
              "                        [ 1.0974e-02,  3.5623e-02,  2.7528e-02]]],\n",
              "              \n",
              "              \n",
              "                      [[[-2.6186e-01, -3.5365e-02, -2.6771e-02],\n",
              "                        [-2.0765e-01,  2.4714e-01,  1.6182e-01],\n",
              "                        [-3.5040e-04,  1.1449e-01,  1.4070e-01]]],\n",
              "              \n",
              "              \n",
              "                      [[[ 1.0750e-02,  1.3882e-01,  3.9747e-02],\n",
              "                        [ 1.6921e-01, -6.9366e-02,  1.6083e-01],\n",
              "                        [-2.9142e-02, -1.7493e-01, -1.2558e-01]]],\n",
              "              \n",
              "              \n",
              "                      [[[-1.1921e-01,  1.4359e-01, -2.5720e-01],\n",
              "                        [-1.7645e-02,  7.3361e-02,  1.5230e-01],\n",
              "                        [ 3.5273e-02,  6.6097e-02,  9.9429e-02]]],\n",
              "              \n",
              "              \n",
              "                      [[[-8.8923e-02,  2.4698e-01,  4.5659e-02],\n",
              "                        [ 2.4238e-01, -5.4864e-02,  1.7007e-01],\n",
              "                        [-2.7261e-01, -5.9969e-03, -2.5140e-01]]],\n",
              "              \n",
              "              \n",
              "                      [[[ 1.1788e-01,  1.5416e-04,  5.8157e-02],\n",
              "                        [-6.0608e-02, -8.6205e-02,  3.2300e-02],\n",
              "                        [-4.3374e-02, -7.7653e-02, -6.0328e-02]]],\n",
              "              \n",
              "              \n",
              "                      [[[ 7.9670e-02,  1.4435e-01,  1.1779e-01],\n",
              "                        [ 6.3570e-02,  1.8778e-01,  6.5323e-02],\n",
              "                        [-1.9092e-01, -1.6685e-01, -4.0897e-02]]],\n",
              "              \n",
              "              \n",
              "                      [[[-1.9134e-02,  7.8752e-03, -1.6155e-01],\n",
              "                        [-8.8185e-03,  1.5030e-01,  2.2047e-01],\n",
              "                        [-2.2918e-01,  3.8409e-02,  8.0433e-02]]],\n",
              "              \n",
              "              \n",
              "                      [[[-1.2027e-01,  1.1385e-01, -9.8482e-02],\n",
              "                        [ 1.1165e-01,  9.5113e-02,  4.4890e-02],\n",
              "                        [ 1.0607e-01,  5.3086e-02, -1.2323e-01]]],\n",
              "              \n",
              "              \n",
              "                      [[[-1.4984e-01, -1.3375e-01,  2.3141e-01],\n",
              "                        [ 1.5365e-02, -3.9753e-02,  3.0032e-01],\n",
              "                        [-2.0651e-01,  2.2799e-02,  1.6475e-01]]],\n",
              "              \n",
              "              \n",
              "                      [[[-1.9487e-01, -2.4101e-02, -1.6514e-02],\n",
              "                        [ 1.6762e-01, -6.3128e-02, -6.7829e-03],\n",
              "                        [-3.6973e-02,  3.0091e-01,  7.7144e-02]]],\n",
              "              \n",
              "              \n",
              "                      [[[ 4.9045e-42, -4.9536e-42,  4.9410e-42],\n",
              "                        [ 4.9059e-42, -4.9354e-42,  4.9144e-42],\n",
              "                        [-4.9200e-42, -4.9214e-42, -4.9158e-42]]],\n",
              "              \n",
              "              \n",
              "                      [[[ 5.6912e-02, -1.0019e-01,  7.7250e-02],\n",
              "                        [ 1.4353e-01,  6.9944e-03,  6.9320e-02],\n",
              "                        [-1.1423e-01, -1.6329e-01, -1.1192e-01]]],\n",
              "              \n",
              "              \n",
              "                      [[[-5.9258e-02,  1.9249e-02, -5.9093e-02],\n",
              "                        [ 3.8310e-02,  1.1408e-01,  5.8449e-02],\n",
              "                        [-3.5383e-02,  4.5068e-02,  9.9167e-02]]],\n",
              "              \n",
              "              \n",
              "                      [[[ 1.9093e-02, -2.2940e-03,  7.9662e-02],\n",
              "                        [-9.0408e-03, -1.9226e-02,  7.0109e-03],\n",
              "                        [ 2.8351e-03, -1.3032e-02, -1.0884e-02]]],\n",
              "              \n",
              "              \n",
              "                      [[[ 1.0631e-01, -1.9595e-01, -2.2940e-01],\n",
              "                        [-3.7517e-02,  1.6763e-01,  4.9996e-03],\n",
              "                        [ 1.9316e-01, -4.1548e-02, -1.0528e-01]]],\n",
              "              \n",
              "              \n",
              "                      [[[ 7.7039e-02,  2.5585e-01, -1.5821e-01],\n",
              "                        [-2.7285e-01,  1.8698e-01,  3.1946e-01],\n",
              "                        [-2.0149e-01, -1.2655e-01, -1.4981e-02]]],\n",
              "              \n",
              "              \n",
              "                      [[[ 6.1063e-02, -3.9502e-02,  1.1194e-01],\n",
              "                        [-3.6262e-02,  5.8025e-02, -1.3486e-01],\n",
              "                        [ 2.7448e-01, -1.3710e-01, -1.3340e-01]]],\n",
              "              \n",
              "              \n",
              "                      [[[-2.4266e-01,  1.6134e-01, -2.6085e-01],\n",
              "                        [ 8.1489e-02,  1.9834e-01,  2.9592e-01],\n",
              "                        [-7.9506e-02, -1.8915e-01,  1.4630e-01]]],\n",
              "              \n",
              "              \n",
              "                      [[[-1.0318e-01, -1.4924e-02,  7.6484e-03],\n",
              "                        [ 7.6733e-02,  6.6449e-02, -1.1107e-01],\n",
              "                        [ 1.4035e-01,  1.4835e-01,  7.7258e-02]]]])),\n",
              "             ('bn1.weight',\n",
              "              tensor([4.0673e-01, 1.9111e-01, 2.9307e-01, 3.0390e-01, 4.0976e-01, 4.1857e-01,\n",
              "                      3.0405e-01, 2.9885e-01, 3.3411e-01, 1.3068e-01, 3.9202e-01, 2.4710e-01,\n",
              "                      1.7422e-01, 3.3836e-01, 1.4489e-01, 4.5885e-01, 3.0631e-01, 1.6021e-01,\n",
              "                      3.8278e-01, 2.4618e-01, 3.2062e-01, 4.2978e-01, 3.4803e-01, 4.9522e-42,\n",
              "                      2.1571e-01, 3.6002e-01, 1.1254e-01, 2.7195e-01, 3.1958e-01, 2.4340e-01,\n",
              "                      2.7052e-01, 4.6022e-01])),\n",
              "             ('bn1.bias',\n",
              "              tensor([ 3.3594e-01,  2.4711e-02,  4.8811e-02,  2.2627e-01,  1.3064e-01,\n",
              "                       2.2677e-01,  2.8439e-01,  1.0991e-01,  1.7576e-01, -2.8584e-02,\n",
              "                       2.1369e-01,  1.9631e-01,  1.3377e-03,  2.8795e-01, -3.3045e-02,\n",
              "                       1.4036e-01,  2.5934e-01, -2.1233e-02,  2.9543e-01,  1.9018e-01,\n",
              "                       7.1208e-02,  1.1806e-01,  3.1985e-01,  4.9424e-42,  9.3101e-03,\n",
              "                       2.4394e-01,  1.1489e-01, -9.0482e-03,  2.9150e-02,  4.8520e-02,\n",
              "                       1.2693e-01,  2.3515e-01])),\n",
              "             ('bn1.running_mean',\n",
              "              tensor([ 1.0591e-02, -3.9995e-03, -9.6174e-03,  2.4860e-03, -1.2277e-02,\n",
              "                      -1.1879e-03,  9.0022e-04, -1.5673e-03,  1.0927e-02, -5.9406e-03,\n",
              "                       9.2831e-03,  8.9837e-03, -6.7239e-04,  5.2345e-03, -6.7574e-03,\n",
              "                       5.0755e-03, -3.2649e-03, -7.5917e-04,  7.6730e-03, -5.4731e-03,\n",
              "                       1.2871e-02,  9.2063e-03, -9.1589e-03, -5.6052e-45,  5.0950e-03,\n",
              "                       5.2249e-03,  1.7963e-03, -6.8108e-04, -1.1433e-04,  9.4384e-04,\n",
              "                       5.1874e-03,  1.6187e-02])),\n",
              "             ('bn1.running_var',\n",
              "              tensor([1.9827e-04, 1.0966e-04, 8.0784e-05, 2.9006e-05, 1.7295e-04, 1.7927e-04,\n",
              "                      9.0124e-05, 8.2558e-05, 1.3388e-04, 4.2438e-05, 2.2022e-04, 2.6187e-04,\n",
              "                      3.9436e-05, 1.4983e-04, 4.5630e-05, 1.3741e-04, 6.1618e-05, 4.4633e-05,\n",
              "                      4.1850e-04, 6.5116e-05, 1.4005e-04, 2.8341e-04, 1.8157e-04, 5.6052e-45,\n",
              "                      4.4872e-05, 2.5497e-04, 5.3983e-07, 8.2851e-05, 8.5681e-05, 1.0487e-05,\n",
              "                      4.2521e-05, 1.7783e-04])),\n",
              "             ('bn1.num_batches_tracked', tensor(38318)),\n",
              "             ('pointwise.weight',\n",
              "              tensor([[[[ 4.9200e-42]],\n",
              "              \n",
              "                       [[ 4.9186e-42]],\n",
              "              \n",
              "                       [[ 4.9059e-42]],\n",
              "              \n",
              "                       ...,\n",
              "              \n",
              "                       [[ 4.9200e-42]],\n",
              "              \n",
              "                       [[-4.9101e-42]],\n",
              "              \n",
              "                       [[-4.9522e-42]]],\n",
              "              \n",
              "              \n",
              "                      [[[ 5.6090e-05]],\n",
              "              \n",
              "                       [[ 2.5665e-02]],\n",
              "              \n",
              "                       [[-6.3165e-03]],\n",
              "              \n",
              "                       ...,\n",
              "              \n",
              "                       [[-4.8513e-02]],\n",
              "              \n",
              "                       [[-2.4009e-02]],\n",
              "              \n",
              "                       [[-9.1119e-02]]],\n",
              "              \n",
              "              \n",
              "                      [[[ 1.2307e-01]],\n",
              "              \n",
              "                       [[ 1.7690e-02]],\n",
              "              \n",
              "                       [[ 9.4334e-02]],\n",
              "              \n",
              "                       ...,\n",
              "              \n",
              "                       [[ 1.3215e-01]],\n",
              "              \n",
              "                       [[ 7.1982e-02]],\n",
              "              \n",
              "                       [[-1.8819e-02]]],\n",
              "              \n",
              "              \n",
              "                      ...,\n",
              "              \n",
              "              \n",
              "                      [[[ 5.5964e-03]],\n",
              "              \n",
              "                       [[ 3.7447e-03]],\n",
              "              \n",
              "                       [[-1.7150e-03]],\n",
              "              \n",
              "                       ...,\n",
              "              \n",
              "                       [[-1.2496e-04]],\n",
              "              \n",
              "                       [[ 3.6106e-04]],\n",
              "              \n",
              "                       [[ 4.1540e-02]]],\n",
              "              \n",
              "              \n",
              "                      [[[-1.1291e-01]],\n",
              "              \n",
              "                       [[-4.3837e-02]],\n",
              "              \n",
              "                       [[ 7.6924e-02]],\n",
              "              \n",
              "                       ...,\n",
              "              \n",
              "                       [[-7.3967e-03]],\n",
              "              \n",
              "                       [[-3.6342e-02]],\n",
              "              \n",
              "                       [[-5.8924e-02]]],\n",
              "              \n",
              "              \n",
              "                      [[[ 2.2143e-04]],\n",
              "              \n",
              "                       [[-1.3727e-04]],\n",
              "              \n",
              "                       [[ 7.3298e-08]],\n",
              "              \n",
              "                       ...,\n",
              "              \n",
              "                       [[ 3.1315e-07]],\n",
              "              \n",
              "                       [[-9.5159e-05]],\n",
              "              \n",
              "                       [[ 1.1914e-03]]]])),\n",
              "             ('bn2.weight',\n",
              "              tensor([4.9256e-42, 4.7985e-02, 6.1030e-02, 9.8693e-02, 4.9410e-42, 4.9522e-42,\n",
              "                      3.3179e-28, 3.3398e-02, 4.9522e-42, 4.9200e-42, 4.6379e-02, 6.9142e-02,\n",
              "                      4.9062e-02, 8.3008e-02, 4.9087e-42, 7.3530e-02, 1.6275e-02, 7.8716e-02,\n",
              "                      5.1020e-02, 5.3519e-02, 5.5909e-02, 4.9312e-42, 1.2378e-01, 7.3358e-02,\n",
              "                      4.9382e-42, 8.7591e-02, 4.9172e-42, 1.8903e-02, 3.5933e-02, 6.6732e-02,\n",
              "                      6.7696e-02, 1.8158e-08, 6.4190e-02, 1.4851e-04, 3.5237e-02, 4.9158e-42,\n",
              "                      1.0482e-01, 3.8599e-02, 4.5826e-02, 4.4756e-02, 4.7904e-02, 4.4057e-02,\n",
              "                      6.8423e-02, 6.4260e-02, 4.9200e-42, 8.8088e-02, 3.5753e-02, 6.9179e-02,\n",
              "                      3.8335e-03, 7.7565e-02, 6.7915e-02, 3.0680e-02, 5.3501e-02, 4.6153e-02,\n",
              "                      8.9292e-02, 5.6884e-02, 4.1579e-02, 7.4350e-02, 1.2670e-02, 6.4245e-02,\n",
              "                      4.9200e-42, 4.1917e-02, 8.8920e-02, 2.9236e-03])),\n",
              "             ('bn2.bias',\n",
              "              tensor([ 4.9354e-42,  5.4023e-02,  1.0941e-01,  1.7925e-02, -4.9480e-42,\n",
              "                      -4.9200e-42,  1.4782e-10,  8.3804e-02,  4.9059e-42, -4.9059e-42,\n",
              "                       9.4027e-02,  5.7602e-02,  8.3493e-02,  6.1893e-02,  4.9438e-42,\n",
              "                       4.9660e-02,  3.8911e-02,  1.2284e-02,  6.3870e-02,  1.4668e-01,\n",
              "                       8.7511e-02, -4.9144e-42, -1.5068e-02,  8.2922e-02,  2.5822e-23,\n",
              "                       4.3883e-02,  4.9298e-42, -7.0259e-03,  4.2560e-02,  8.2802e-02,\n",
              "                       4.9672e-02,  2.3371e-08,  1.1012e-01,  2.5317e-11,  7.4552e-02,\n",
              "                       4.9340e-42,  7.5298e-03,  7.8701e-02,  8.5388e-02,  7.3068e-02,\n",
              "                       1.1208e-01,  8.9984e-02, -6.7004e-02,  4.4012e-02, -4.9228e-42,\n",
              "                      -2.3514e-02,  7.8501e-02,  1.6094e-02, -4.4116e-03,  6.5654e-02,\n",
              "                       1.3915e-01, -3.3941e-02,  1.0897e-01,  1.2369e-01,  7.7875e-02,\n",
              "                       1.1256e-01,  1.2118e-01,  5.2612e-02,  4.0328e-02,  6.9288e-02,\n",
              "                      -4.9298e-42, -1.1102e-01,  4.7455e-02,  3.8886e-06])),\n",
              "             ('bn2.running_mean',\n",
              "              tensor([ 5.6052e-45,  5.6348e-03,  7.3260e-03,  1.0535e-01, -2.0781e-42,\n",
              "                      -2.8082e-42,  2.7021e-19, -2.9937e-02,  5.6052e-45, -5.6052e-45,\n",
              "                       2.4916e-02,  8.1464e-02, -8.7154e-02, -3.2996e-02,  5.6052e-45,\n",
              "                       1.0404e-01, -5.1506e-02, -1.0624e-02, -1.3187e-02,  8.1209e-02,\n",
              "                       4.6488e-03, -8.8562e-43,  1.7718e-01,  4.8737e-02, -2.0781e-42,\n",
              "                      -6.7778e-03, -5.6052e-45,  3.9260e-02,  3.4590e-03, -6.5670e-02,\n",
              "                       1.1005e-02, -2.3022e-12,  4.5531e-02,  1.4664e-08, -5.0567e-02,\n",
              "                       5.6052e-45,  1.1145e-01, -2.7627e-02,  2.3821e-02,  3.1503e-02,\n",
              "                      -2.1405e-02, -3.7276e-02,  2.1192e-01,  3.3316e-02,  1.6115e-42,\n",
              "                       9.0072e-02,  3.1163e-02, -1.5918e-02,  6.2771e-04, -4.5743e-04,\n",
              "                       1.2678e-01,  4.8683e-02, -3.8880e-02, -7.1951e-02,  1.1759e-01,\n",
              "                       3.5971e-02, -7.8900e-02, -1.2320e-02, -6.4386e-03,  5.7013e-03,\n",
              "                      -5.6052e-45,  4.0606e-02, -5.0342e-02,  3.8165e-03])),\n",
              "             ('bn2.running_var',\n",
              "              tensor([5.6052e-45, 1.1812e-02, 2.3577e-02, 2.9855e-02, 5.6052e-45, 5.6052e-45,\n",
              "                      9.8952e-38, 1.3828e-02, 5.6052e-45, 5.6052e-45, 2.6124e-02, 1.7384e-02,\n",
              "                      8.4921e-03, 2.2026e-02, 5.6052e-45, 1.0232e-02, 2.0030e-03, 7.5810e-03,\n",
              "                      7.8857e-03, 1.4078e-02, 1.8456e-02, 5.6052e-45, 3.8170e-02, 2.9868e-02,\n",
              "                      5.6052e-45, 1.4786e-02, 5.6052e-45, 6.0365e-04, 2.6388e-03, 2.9288e-02,\n",
              "                      1.1948e-02, 3.8279e-23, 2.0596e-02, 4.2631e-16, 6.6297e-03, 5.6052e-45,\n",
              "                      2.6921e-02, 9.1171e-03, 9.3601e-03, 1.4562e-02, 1.0275e-02, 1.7951e-02,\n",
              "                      1.9699e-02, 5.4355e-03, 5.6052e-45, 1.2526e-02, 7.6567e-03, 5.2355e-03,\n",
              "                      5.4173e-07, 2.5943e-02, 5.0298e-02, 2.9451e-03, 1.2412e-02, 1.4281e-02,\n",
              "                      2.6444e-02, 2.0331e-02, 7.6887e-03, 6.5785e-03, 2.1663e-03, 1.0668e-02,\n",
              "                      5.6052e-45, 1.4106e-03, 1.6538e-02, 8.8833e-06])),\n",
              "             ('bn2.num_batches_tracked', tensor(38318))])"
            ]
          },
          "metadata": {},
          "execution_count": 26
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "lr_scheduler = CosineAnnealingLR(optimizer1, T_max=500)\n",
        "##Training and Testing Loop\n",
        "\n",
        "\n",
        "#Training Loop\n",
        "\n",
        "from tqdm.auto import tqdm\n",
        "import torch\n",
        "\n",
        "train_loss_list=[]\n",
        "train_acc_list=[]\n",
        "test_loss_list=[]\n",
        "test_acc_list=[]\n",
        "\n",
        "epochs=50 #epochs\n",
        "best_acc=0\n",
        "patience=70\n",
        "max_patience_after_revert = 30\n",
        "current_patience=0\n",
        "\n",
        "from pathlib import Path\n",
        "model_path=Path(\"models\")\n",
        "model_path.mkdir(parents=True,exist_ok=True)\n",
        "model_name=\"best_model_small.pth\" #modelname\n",
        "model_save_path=model_path/model_name\n",
        "\n",
        "\n",
        "\n",
        "# Create model save\n",
        "\n",
        "\n",
        "reverted=False\n",
        "start_timer=timer()\n",
        "for epoch in tqdm(range(epochs)):\n",
        "  train_loss,train_acc=training(data_loader=train_dataloader,model=model_small,loss_fn=loss_fn,optimizer=optimizer1,accuracy_fn=accuracy_fn)\n",
        "  test_loss,test_acc=testing(data_loader=test_dataloader,model=model_small,loss_fn=loss_fn,accuracy_fn=accuracy_fn)\n",
        "  print(f\"Epoch:{epoch}\")\n",
        "\n",
        "  if (test_acc>best_acc):\n",
        "    best_acc=test_acc\n",
        "    model_small.state_dict()\n",
        "    best_model_state_dict=model.state_dict()\n",
        "    torch.save(model_small.state_dict(),f=model_save_path)\n",
        "    print(f\"New best test loss is {test_acc}. Model Saved\")\n",
        "    current_patience=0 #reset patience\n",
        "    patience_after_revert=0\n",
        "    reverted=False\n",
        "  else:\n",
        "    current_patience+=1\n",
        "\n",
        "    if current_patience>=patience and not reverted:\n",
        "      print(f\"No improvement for{patience} epochs. Reverting to the best model\")\n",
        "      model.load_state_dict(best_model_state_dict)\n",
        "      patience_after_revert=0\n",
        "      reverted=True\n",
        "\n",
        "  if reverted:\n",
        "    patience_after_revert+=1\n",
        "    if patience_after_revert>=max_patience_after_revert:\n",
        "      print(f\"Continue for {max_patience_after_revert} epochs after revert\")\n",
        "\n",
        "      if test_acc>=best_acc:\n",
        "       print(\"Test loss still not improving reverting to best model\")\n",
        "       model.load_state_dict(best_model_state_dict)\n",
        "      patience_after_revert=0\n",
        "\n",
        "\n",
        "from pathlib import Path\n",
        "model_path=Path(\"models\")\n",
        "model_path.mkdir(parents=True,exist_ok=True)\n",
        "model_name=\"last_model_small.pth\" #modelname\n",
        "model_save_path=model_path/model_name\n",
        "# Create model save\n",
        "\n",
        "\n",
        "torch.save(model_small.state_dict(),f=model_save_path)\n",
        "print(f\"Last model is saved with test loss:{test_acc}\")\n",
        "model_small.state_dict()\n",
        "\n",
        "end_timer=timer()\n",
        "print_train_time(start=start_timer,end=end_timer,device=device)\n"
      ],
      "metadata": {
        "id": "y2PonmQnsV2X",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000,
          "referenced_widgets": [
            "ab2d63b799874a0385dbb2c47c4089dd",
            "5826fca10a6645ed9503fb57bc9daede",
            "79c22097c0fb4231bff351ed2d921940",
            "7a453f0b520946ccac400d3b18d1f76f",
            "7e1b77efdbd141149e9c0b3740c510a9",
            "fa5475d6750249beb845079d57b49d0f",
            "f85428dee9234a66b74b64fe7d538ea5",
            "16cfb29b23ad4f90950054b2eb16be97",
            "1d71657663324e9e8509294a6ff64eb0",
            "162018274a664da79e562b128c633a93",
            "79133a4b017348a4b4f129fc4e5324aa"
          ]
        },
        "outputId": "5544dc1b-0403-4509-d87e-d0c18584a394"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "  0%|          | 0/50 [00:00<?, ?it/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "ab2d63b799874a0385dbb2c47c4089dd"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train Loss:1.283506|Train Acc:59.528852%\n",
            "Test loss: 0.90480 | Test accuracy: 70.73%\n",
            "\n",
            "Epoch:0\n",
            "New best test loss is 70.73049363057325. Model Saved\n",
            "Train Loss:0.772497|Train Acc:74.984015%\n",
            "Test loss: 0.72587 | Test accuracy: 75.43%\n",
            "\n",
            "Epoch:1\n",
            "New best test loss is 75.42794585987261. Model Saved\n",
            "Train Loss:0.617066|Train Acc:79.729460%\n",
            "Test loss: 0.60499 | Test accuracy: 79.85%\n",
            "\n",
            "Epoch:2\n",
            "New best test loss is 79.8467356687898. Model Saved\n",
            "Train Loss:0.535325|Train Acc:82.348945%\n",
            "Test loss: 0.56171 | Test accuracy: 80.49%\n",
            "\n",
            "Epoch:3\n",
            "New best test loss is 80.49363057324841. Model Saved\n",
            "Train Loss:0.482734|Train Acc:84.089274%\n",
            "Test loss: 0.51002 | Test accuracy: 82.38%\n",
            "\n",
            "Epoch:4\n",
            "New best test loss is 82.38455414012739. Model Saved\n",
            "Train Loss:0.455817|Train Acc:84.730659%\n",
            "Test loss: 0.48121 | Test accuracy: 83.57%\n",
            "\n",
            "Epoch:5\n",
            "New best test loss is 83.56886942675159. Model Saved\n",
            "Train Loss:0.425882|Train Acc:85.901535%\n",
            "Test loss: 0.46729 | Test accuracy: 84.41%\n",
            "\n",
            "Epoch:6\n",
            "New best test loss is 84.41480891719745. Model Saved\n",
            "Train Loss:0.411502|Train Acc:86.351103%\n",
            "Test loss: 0.45199 | Test accuracy: 84.70%\n",
            "\n",
            "Epoch:7\n",
            "New best test loss is 84.70342356687898. Model Saved\n",
            "Train Loss:0.389066|Train Acc:87.030451%\n",
            "Test loss: 0.42450 | Test accuracy: 86.13%\n",
            "\n",
            "Epoch:8\n",
            "New best test loss is 86.1265923566879. Model Saved\n",
            "Train Loss:0.377109|Train Acc:87.454044%\n",
            "Test loss: 0.42976 | Test accuracy: 85.44%\n",
            "\n",
            "Epoch:9\n",
            "Train Loss:0.365995|Train Acc:87.749760%\n",
            "Test loss: 0.42551 | Test accuracy: 85.69%\n",
            "\n",
            "Epoch:10\n",
            "Train Loss:0.355564|Train Acc:88.099425%\n",
            "Test loss: 0.43046 | Test accuracy: 85.19%\n",
            "\n",
            "Epoch:11\n",
            "Train Loss:0.350002|Train Acc:88.145380%\n",
            "Test loss: 0.40899 | Test accuracy: 86.05%\n",
            "\n",
            "Epoch:12\n",
            "Train Loss:0.339672|Train Acc:88.469070%\n",
            "Test loss: 0.42451 | Test accuracy: 85.59%\n",
            "\n",
            "Epoch:13\n",
            "Train Loss:0.332594|Train Acc:88.850703%\n",
            "Test loss: 0.39484 | Test accuracy: 86.52%\n",
            "\n",
            "Epoch:14\n",
            "New best test loss is 86.52468152866243. Model Saved\n",
            "Train Loss:0.325979|Train Acc:89.014546%\n",
            "Test loss: 0.40805 | Test accuracy: 86.44%\n",
            "\n",
            "Epoch:15\n",
            "Train Loss:0.317574|Train Acc:89.326247%\n",
            "Test loss: 0.37216 | Test accuracy: 87.23%\n",
            "\n",
            "Epoch:16\n",
            "New best test loss is 87.2312898089172. Model Saved\n",
            "Train Loss:0.314308|Train Acc:89.516065%\n",
            "Test loss: 0.42757 | Test accuracy: 85.54%\n",
            "\n",
            "Epoch:17\n",
            "Train Loss:0.307779|Train Acc:89.695892%\n",
            "Test loss: 0.38090 | Test accuracy: 87.18%\n",
            "\n",
            "Epoch:18\n",
            "Train Loss:0.303846|Train Acc:89.903692%\n",
            "Test loss: 0.41056 | Test accuracy: 85.97%\n",
            "\n",
            "Epoch:19\n",
            "Train Loss:0.298047|Train Acc:90.143462%\n",
            "Test loss: 0.39372 | Test accuracy: 86.56%\n",
            "\n",
            "Epoch:20\n",
            "Train Loss:0.296709|Train Acc:90.165441%\n",
            "Test loss: 0.38570 | Test accuracy: 86.87%\n",
            "\n",
            "Epoch:21\n",
            "Train Loss:0.291790|Train Acc:90.251359%\n",
            "Test loss: 0.39628 | Test accuracy: 86.46%\n",
            "\n",
            "Epoch:22\n",
            "Train Loss:0.286177|Train Acc:90.509111%\n",
            "Test loss: 0.42754 | Test accuracy: 85.35%\n",
            "\n",
            "Epoch:23\n",
            "Train Loss:0.285455|Train Acc:90.459159%\n",
            "Test loss: 0.38375 | Test accuracy: 87.12%\n",
            "\n",
            "Epoch:24\n",
            "Train Loss:0.286315|Train Acc:90.391224%\n",
            "Test loss: 0.40860 | Test accuracy: 86.11%\n",
            "\n",
            "Epoch:25\n",
            "Train Loss:0.279385|Train Acc:90.774856%\n",
            "Test loss: 0.35838 | Test accuracy: 88.03%\n",
            "\n",
            "Epoch:26\n",
            "New best test loss is 88.02746815286625. Model Saved\n",
            "Train Loss:0.272376|Train Acc:90.886749%\n",
            "Test loss: 0.35101 | Test accuracy: 88.47%\n",
            "\n",
            "Epoch:27\n",
            "New best test loss is 88.46536624203821. Model Saved\n",
            "Train Loss:0.274866|Train Acc:90.840793%\n",
            "Test loss: 0.36615 | Test accuracy: 87.72%\n",
            "\n",
            "Epoch:28\n",
            "Train Loss:0.268590|Train Acc:91.018622%\n",
            "Test loss: 0.37858 | Test accuracy: 87.19%\n",
            "\n",
            "Epoch:29\n",
            "Train Loss:0.265723|Train Acc:91.210438%\n",
            "Test loss: 0.36034 | Test accuracy: 87.51%\n",
            "\n",
            "Epoch:30\n",
            "Train Loss:0.262741|Train Acc:91.152494%\n",
            "Test loss: 0.35105 | Test accuracy: 88.21%\n",
            "\n",
            "Epoch:31\n",
            "Train Loss:0.259182|Train Acc:91.264386%\n",
            "Test loss: 0.42849 | Test accuracy: 85.13%\n",
            "\n",
            "Epoch:32\n",
            "Train Loss:0.259117|Train Acc:91.250400%\n",
            "Test loss: 0.36370 | Test accuracy: 87.30%\n",
            "\n",
            "Epoch:33\n",
            "Train Loss:0.256998|Train Acc:91.370285%\n",
            "Test loss: 0.35047 | Test accuracy: 88.23%\n",
            "\n",
            "Epoch:34\n",
            "Train Loss:0.255488|Train Acc:91.578085%\n",
            "Test loss: 0.35540 | Test accuracy: 87.72%\n",
            "\n",
            "Epoch:35\n",
            "Train Loss:0.250512|Train Acc:91.731937%\n",
            "Test loss: 0.38588 | Test accuracy: 86.89%\n",
            "\n",
            "Epoch:36\n",
            "Train Loss:0.250033|Train Acc:91.709958%\n",
            "Test loss: 0.37979 | Test accuracy: 86.93%\n",
            "\n",
            "Epoch:37\n",
            "Train Loss:0.248857|Train Acc:91.703964%\n",
            "Test loss: 0.35065 | Test accuracy: 88.34%\n",
            "\n",
            "Epoch:38\n",
            "Train Loss:0.249420|Train Acc:91.604060%\n",
            "Test loss: 0.36105 | Test accuracy: 87.82%\n",
            "\n",
            "Epoch:39\n",
            "Train Loss:0.242544|Train Acc:91.937740%\n",
            "Test loss: 0.36808 | Test accuracy: 87.57%\n",
            "\n",
            "Epoch:40\n",
            "Train Loss:0.248459|Train Acc:91.779891%\n",
            "Test loss: 0.36443 | Test accuracy: 87.52%\n",
            "\n",
            "Epoch:41\n",
            "Train Loss:0.243028|Train Acc:92.079604%\n",
            "Test loss: 0.36330 | Test accuracy: 87.65%\n",
            "\n",
            "Epoch:42\n",
            "Train Loss:0.240918|Train Acc:92.011669%\n",
            "Test loss: 0.33259 | Test accuracy: 88.80%\n",
            "\n",
            "Epoch:43\n",
            "New best test loss is 88.80374203821655. Model Saved\n",
            "Train Loss:0.237358|Train Acc:92.219469%\n",
            "Test loss: 0.36257 | Test accuracy: 87.80%\n",
            "\n",
            "Epoch:44\n",
            "Train Loss:0.238066|Train Acc:92.217471%\n",
            "Test loss: 0.39014 | Test accuracy: 86.64%\n",
            "\n",
            "Epoch:45\n",
            "Train Loss:0.236784|Train Acc:92.029652%\n",
            "Test loss: 0.36033 | Test accuracy: 88.20%\n",
            "\n",
            "Epoch:46\n",
            "Train Loss:0.235641|Train Acc:92.263427%\n",
            "Test loss: 0.37457 | Test accuracy: 87.46%\n",
            "\n",
            "Epoch:47\n",
            "Train Loss:0.235077|Train Acc:92.069613%\n",
            "Test loss: 0.35851 | Test accuracy: 88.09%\n",
            "\n",
            "Epoch:48\n",
            "Train Loss:0.230737|Train Acc:92.437260%\n",
            "Test loss: 0.36009 | Test accuracy: 87.95%\n",
            "\n",
            "Epoch:49\n",
            "Last model is saved with test loss:87.94785031847134\n",
            "Train time on cuda: 4201.673 seconds\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "4201.673362150001"
            ]
          },
          "metadata": {},
          "execution_count": 31
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def testing(data_loader:DataLoader,model:torch.nn.Module,loss_fn:torch.nn.Module,accuracy_fn,device:torch.device=device):\n",
        "  test_loss,test_acc=0,0\n",
        "  model.to(device)\n",
        "  model.eval()\n",
        "\n",
        "  with torch.inference_mode():\n",
        "    for X,y in data_loader:\n",
        "      X,y=X.float().to(device),y.to(device)\n",
        "\n",
        "      test_pred=model(X)\n",
        "\n",
        "      test_loss=test_loss+loss_fn(test_pred,y)\n",
        "      y_pred_class=torch.argmax(torch.softmax(test_pred,dim=1),dim=1)\n",
        "      test_acc=test_acc+accuracy_fn(y_target=y,y_pred=y_pred_class)\n",
        "\n",
        "    test_loss/=len(data_loader)\n",
        "    test_acc/=len(data_loader)\n",
        "\n",
        "    print(f\"Test loss: {test_loss:.5f} | Test accuracy: {test_acc:.2f}%\\n\")\n",
        "\n",
        "    return test_loss,test_acc\n",
        "\n",
        "# This is when conitnuing training of a previously saved model\n",
        "from pathlib import Path\n",
        "model_path=Path(\"models\")\n",
        "model_path.mkdir(parents=True,exist_ok=True)\n",
        "model_name=\"best_model_small_07052024.pth\" #modelname\n",
        "model_save_path=model_path/model_name\n",
        "\n",
        "#Load testing\n",
        "sigmoid=nn.Sigmoid()\n",
        "loss_fn=nn.CrossEntropyLoss()#Loss Function\n",
        "\n",
        "\n",
        "\n",
        "model_small=MobileNetV1_prunedblock6()\n",
        "model_small.load_state_dict(torch.load(f=model_save_path))\n",
        "#model_load.state_dict()\n",
        "optimizer1=torch.optim.Adam(params=model_small.parameters(),lr=0.001,weight_decay=0.000) #Optimizer\n",
        "\n",
        "\n",
        "lr_scheduler = CosineAnnealingLR(optimizer1, T_max=500)\n",
        "start_timer=timer()\n",
        "test_loss,test_acc=testing(data_loader=test_dataloader,model=model_small,loss_fn=loss_fn,accuracy_fn=accuracy_fn)\n",
        "best_loss=test_loss\n",
        "best_loss\n",
        "end_timer=timer()\n",
        "print_test_time(start=start_timer,end=end_timer,device=device)"
      ],
      "metadata": {
        "id": "6qZA_XjN9ai0",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "452263af-cda4-480b-fec1-cf9f5984a65f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Test loss: 0.33259 | Test accuracy: 88.80%\n",
            "\n",
            "Test time on cuda: 9.756 seconds\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "9.756414778000021"
            ]
          },
          "metadata": {},
          "execution_count": 32
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Train small network from Random initialization"
      ],
      "metadata": {
        "id": "yrNuqZBw9ODr"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Trained the pruned network without copying initialization from the original network. The pruned network is trained with random values initialized."
      ],
      "metadata": {
        "id": "MWbtDK5mvzTQ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "test=img\n",
        "test.shape\n",
        "model_small_random=MobileNetV1_prunedblock6()\n",
        "test_input=test\n",
        "test_input.shape\n",
        "test_model=model_small_random(test_input)\n",
        "test_model.shape\n",
        "\n",
        "total_params = sum(p.numel() for p in model_small_random.parameters())\n",
        "print(\"Total number of parameters: \", total_params)\n",
        "\n",
        "loss_fn=nn.CrossEntropyLoss()#Loss Function\n",
        "\n",
        "\n",
        "optimizer1=torch.optim.Adam(params=model_small_random.parameters(),lr=0.0005,weight_decay=0.001) #Optimizer\n",
        "\n",
        "\n",
        "lr_scheduler = CosineAnnealingLR(optimizer1, T_max=500)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "i5gRgq3o9MxT",
        "outputId": "b4eadc70-5bd4-4a66-9427-d1d191f56685"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Total number of parameters:  310794\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "summary(model_small_random, input_size=(1, 3, 224, 224))"
      ],
      "metadata": {
        "id": "ZR-QEU7FAWrj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "lr_scheduler = CosineAnnealingLR(optimizer1, T_max=500)\n",
        "##Training and Testing Loop\n",
        "\n",
        "\n",
        "#Training Loop\n",
        "\n",
        "from tqdm.auto import tqdm\n",
        "import torch\n",
        "\n",
        "train_loss_list=[]\n",
        "train_acc_list=[]\n",
        "test_loss_list=[]\n",
        "test_acc_list=[]\n",
        "\n",
        "epochs=50 #epochs\n",
        "best_acc=0\n",
        "patience=70\n",
        "max_patience_after_revert = 30\n",
        "current_patience=0\n",
        "\n",
        "from pathlib import Path\n",
        "model_path=Path(\"models\")\n",
        "model_path.mkdir(parents=True,exist_ok=True)\n",
        "model_name=\"best_model_small_random.pth\" #modelname\n",
        "model_save_path=model_path/model_name\n",
        "\n",
        "\n",
        "\n",
        "# Create model save\n",
        "\n",
        "\n",
        "reverted=False\n",
        "start_timer=timer()\n",
        "for epoch in tqdm(range(epochs)):\n",
        "  train_loss,train_acc=training(data_loader=train_dataloader,model=model_small_random,loss_fn=loss_fn,optimizer=optimizer1,accuracy_fn=accuracy_fn)\n",
        "  test_loss,test_acc=testing(data_loader=test_dataloader,model=model_small_random,loss_fn=loss_fn,accuracy_fn=accuracy_fn)\n",
        "  print(f\"Epoch:{epoch}\")\n",
        "\n",
        "  if (test_acc>best_acc):\n",
        "    best_acc=test_acc\n",
        "    model_small.state_dict()\n",
        "    best_model_state_dict=model.state_dict()\n",
        "    torch.save(model_small.state_dict(),f=model_save_path)\n",
        "    print(f\"New best test loss is {test_acc}. Model Saved\")\n",
        "    current_patience=0 #reset patience\n",
        "    patience_after_revert=0\n",
        "    reverted=False\n",
        "  else:\n",
        "    current_patience+=1\n",
        "\n",
        "    if current_patience>=patience and not reverted:\n",
        "      print(f\"No improvement for{patience} epochs. Reverting to the best model\")\n",
        "      model.load_state_dict(best_model_state_dict)\n",
        "      patience_after_revert=0\n",
        "      reverted=True\n",
        "\n",
        "  if reverted:\n",
        "    patience_after_revert+=1\n",
        "    if patience_after_revert>=max_patience_after_revert:\n",
        "      print(f\"Continue for {max_patience_after_revert} epochs after revert\")\n",
        "\n",
        "      if test_acc>=best_acc:\n",
        "       print(\"Test loss still not improving reverting to best model\")\n",
        "       model.load_state_dict(best_model_state_dict)\n",
        "      patience_after_revert=0\n",
        "\n",
        "\n",
        "from pathlib import Path\n",
        "model_path=Path(\"models\")\n",
        "model_path.mkdir(parents=True,exist_ok=True)\n",
        "model_name=\"last_model_small_random.pth\" #modelname\n",
        "model_save_path=model_path/model_name\n",
        "# Create model save\n",
        "\n",
        "\n",
        "torch.save(model_small.state_dict(),f=model_save_path)\n",
        "print(f\"Last model is saved with test loss:{test_acc}\")\n",
        "model_small.state_dict()\n",
        "\n",
        "end_timer=timer()\n",
        "print_train_time(start=start_timer,end=end_timer,device=device)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000,
          "referenced_widgets": [
            "6b507f1a64534c1fb2d4f2d79bc47b49",
            "2e1c51ab48b443849a9882f539b1ffd8",
            "6ad91ab7e37943debcba5cd8a337e548",
            "3d8f9b49e55447fcb4e2791ee8d3da78",
            "c15c3367b1d74b94a900519890fcbfd9",
            "3717d5db78a444cbb4655a623f2853aa",
            "bf709072725c450aa755de20f9f543e0",
            "50785a7f072c426c939607cf3018d010",
            "6943a618d7394082a088e6bf33e6f217",
            "24e1dca3f91c44ce8ec87022c0aa48eb",
            "d6ada38698284c018ce6227f81e5b699"
          ]
        },
        "id": "FoNKnWWBAeKL",
        "outputId": "f02fb781-1207-4d9c-82b0-7050121b8db6"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "  0%|          | 0/50 [00:00<?, ?it/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "6b507f1a64534c1fb2d4f2d79bc47b49"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train Loss:1.559261|Train Acc:46.635230%\n",
            "Test loss: 1.21557 | Test accuracy: 56.86%\n",
            "\n",
            "Epoch:0\n",
            "New best test loss is 56.857085987261144. Model Saved\n",
            "Train Loss:1.027460|Train Acc:64.663923%\n",
            "Test loss: 0.91895 | Test accuracy: 68.62%\n",
            "\n",
            "Epoch:1\n",
            "New best test loss is 68.62062101910828. Model Saved\n",
            "Train Loss:0.828577|Train Acc:71.795077%\n",
            "Test loss: 0.81014 | Test accuracy: 71.87%\n",
            "\n",
            "Epoch:2\n",
            "New best test loss is 71.86504777070064. Model Saved\n",
            "Train Loss:0.702913|Train Acc:76.276774%\n",
            "Test loss: 0.70300 | Test accuracy: 76.21%\n",
            "\n",
            "Epoch:3\n",
            "New best test loss is 76.21417197452229. Model Saved\n",
            "Train Loss:0.622189|Train Acc:78.990169%\n",
            "Test loss: 0.60140 | Test accuracy: 80.16%\n",
            "\n",
            "Epoch:4\n",
            "New best test loss is 80.15525477707007. Model Saved\n",
            "Train Loss:0.562367|Train Acc:81.066176%\n",
            "Test loss: 0.55870 | Test accuracy: 80.62%\n",
            "\n",
            "Epoch:5\n",
            "New best test loss is 80.62300955414013. Model Saved\n",
            "Train Loss:0.516452|Train Acc:82.606698%\n",
            "Test loss: 0.52745 | Test accuracy: 81.71%\n",
            "\n",
            "Epoch:6\n",
            "New best test loss is 81.7078025477707. Model Saved\n",
            "Train Loss:0.484011|Train Acc:83.659687%\n",
            "Test loss: 0.51780 | Test accuracy: 82.04%\n",
            "\n",
            "Epoch:7\n",
            "New best test loss is 82.03622611464968. Model Saved\n",
            "Train Loss:0.460490|Train Acc:84.636749%\n",
            "Test loss: 0.48676 | Test accuracy: 83.19%\n",
            "\n",
            "Epoch:8\n",
            "New best test loss is 83.1906847133758. Model Saved\n",
            "Train Loss:0.435339|Train Acc:85.286125%\n",
            "Test loss: 0.49113 | Test accuracy: 83.13%\n",
            "\n",
            "Epoch:9\n",
            "Train Loss:0.415313|Train Acc:85.991448%\n",
            "Test loss: 0.46491 | Test accuracy: 84.24%\n",
            "\n",
            "Epoch:10\n",
            "New best test loss is 84.23566878980891. Model Saved\n",
            "Train Loss:0.399031|Train Acc:86.704763%\n",
            "Test loss: 0.48672 | Test accuracy: 83.55%\n",
            "\n",
            "Epoch:11\n",
            "Train Loss:0.381398|Train Acc:87.394102%\n",
            "Test loss: 0.45566 | Test accuracy: 84.19%\n",
            "\n",
            "Epoch:12\n",
            "Train Loss:0.368212|Train Acc:87.679827%\n",
            "Test loss: 0.47534 | Test accuracy: 83.56%\n",
            "\n",
            "Epoch:13\n",
            "Train Loss:0.358686|Train Acc:88.103421%\n",
            "Test loss: 0.43306 | Test accuracy: 85.14%\n",
            "\n",
            "Epoch:14\n",
            "New best test loss is 85.14132165605096. Model Saved\n",
            "Train Loss:0.348887|Train Acc:88.193334%\n",
            "Test loss: 0.43313 | Test accuracy: 85.52%\n",
            "\n",
            "Epoch:15\n",
            "New best test loss is 85.51950636942675. Model Saved\n",
            "Train Loss:0.344384|Train Acc:88.493047%\n",
            "Test loss: 0.42901 | Test accuracy: 85.49%\n",
            "\n",
            "Epoch:16\n",
            "Train Loss:0.332054|Train Acc:88.930627%\n",
            "Test loss: 0.44973 | Test accuracy: 84.37%\n",
            "\n",
            "Epoch:17\n",
            "Train Loss:0.323128|Train Acc:89.298274%\n",
            "Test loss: 0.39762 | Test accuracy: 86.32%\n",
            "\n",
            "Epoch:18\n",
            "New best test loss is 86.3156847133758. Model Saved\n",
            "Train Loss:0.317151|Train Acc:89.504076%\n",
            "Test loss: 0.44375 | Test accuracy: 85.18%\n",
            "\n",
            "Epoch:19\n",
            "Train Loss:0.312877|Train Acc:89.669917%\n",
            "Test loss: 0.38751 | Test accuracy: 86.90%\n",
            "\n",
            "Epoch:20\n",
            "New best test loss is 86.90286624203821. Model Saved\n",
            "Train Loss:0.303707|Train Acc:90.009591%\n",
            "Test loss: 0.41099 | Test accuracy: 85.41%\n",
            "\n",
            "Epoch:21\n",
            "Train Loss:0.300378|Train Acc:89.965633%\n",
            "Test loss: 0.43378 | Test accuracy: 85.01%\n",
            "\n",
            "Epoch:22\n",
            "Train Loss:0.292472|Train Acc:90.243366%\n",
            "Test loss: 0.38694 | Test accuracy: 86.70%\n",
            "\n",
            "Epoch:23\n",
            "Train Loss:0.288730|Train Acc:90.377238%\n",
            "Test loss: 0.41925 | Test accuracy: 85.51%\n",
            "\n",
            "Epoch:24\n",
            "Train Loss:0.279736|Train Acc:90.684942%\n",
            "Test loss: 0.40606 | Test accuracy: 86.30%\n",
            "\n",
            "Epoch:25\n",
            "Train Loss:0.275338|Train Acc:90.818814%\n",
            "Test loss: 0.39574 | Test accuracy: 86.53%\n",
            "\n",
            "Epoch:26\n",
            "Train Loss:0.272997|Train Acc:90.876758%\n",
            "Test loss: 0.37832 | Test accuracy: 86.66%\n",
            "\n",
            "Epoch:27\n",
            "Train Loss:0.270570|Train Acc:90.934703%\n",
            "Test loss: 0.43405 | Test accuracy: 85.48%\n",
            "\n",
            "Epoch:28\n",
            "Train Loss:0.266833|Train Acc:91.106538%\n",
            "Test loss: 0.37041 | Test accuracy: 87.21%\n",
            "\n",
            "Epoch:29\n",
            "New best test loss is 87.21138535031847. Model Saved\n",
            "Train Loss:0.264809|Train Acc:91.254396%\n",
            "Test loss: 0.38031 | Test accuracy: 87.22%\n",
            "\n",
            "Epoch:30\n",
            "New best test loss is 87.22133757961784. Model Saved\n",
            "Train Loss:0.258962|Train Acc:91.292359%\n",
            "Test loss: 0.35680 | Test accuracy: 87.75%\n",
            "\n",
            "Epoch:31\n",
            "New best test loss is 87.74880573248407. Model Saved\n",
            "Train Loss:0.254713|Train Acc:91.610054%\n",
            "Test loss: 0.37948 | Test accuracy: 87.11%\n",
            "\n",
            "Epoch:32\n",
            "Train Loss:0.253855|Train Acc:91.554108%\n",
            "Test loss: 0.41597 | Test accuracy: 85.87%\n",
            "\n",
            "Epoch:33\n",
            "Train Loss:0.249848|Train Acc:91.887788%\n",
            "Test loss: 0.36469 | Test accuracy: 87.71%\n",
            "\n",
            "Epoch:34\n",
            "Train Loss:0.247365|Train Acc:91.759910%\n",
            "Test loss: 0.37289 | Test accuracy: 87.49%\n",
            "\n",
            "Epoch:35\n",
            "Train Loss:0.243427|Train Acc:91.857816%\n",
            "Test loss: 0.38433 | Test accuracy: 86.60%\n",
            "\n",
            "Epoch:36\n",
            "Train Loss:0.238681|Train Acc:92.063619%\n",
            "Test loss: 0.34583 | Test accuracy: 87.98%\n",
            "\n",
            "Epoch:37\n",
            "New best test loss is 87.97770700636943. Model Saved\n",
            "Train Loss:0.240099|Train Acc:92.095588%\n",
            "Test loss: 0.35726 | Test accuracy: 87.83%\n",
            "\n",
            "Epoch:38\n",
            "Train Loss:0.237138|Train Acc:92.047634%\n",
            "Test loss: 0.37539 | Test accuracy: 87.25%\n",
            "\n",
            "Epoch:39\n",
            "Train Loss:0.232670|Train Acc:92.097586%\n",
            "Test loss: 0.37505 | Test accuracy: 87.50%\n",
            "\n",
            "Epoch:40\n",
            "Train Loss:0.231138|Train Acc:92.407289%\n",
            "Test loss: 0.34388 | Test accuracy: 87.95%\n",
            "\n",
            "Epoch:41\n",
            "Train Loss:0.226209|Train Acc:92.619086%\n",
            "Test loss: 0.38478 | Test accuracy: 86.81%\n",
            "\n",
            "Epoch:42\n",
            "Train Loss:0.229930|Train Acc:92.463235%\n",
            "Test loss: 0.36210 | Test accuracy: 87.89%\n",
            "\n",
            "Epoch:43\n",
            "Train Loss:0.228846|Train Acc:92.483216%\n",
            "Test loss: 0.36619 | Test accuracy: 87.49%\n",
            "\n",
            "Epoch:44\n",
            "Train Loss:0.225397|Train Acc:92.565137%\n",
            "Test loss: 0.35909 | Test accuracy: 88.00%\n",
            "\n",
            "Epoch:45\n",
            "New best test loss is 87.99761146496816. Model Saved\n",
            "Train Loss:0.224743|Train Acc:92.611093%\n",
            "Test loss: 0.36065 | Test accuracy: 88.00%\n",
            "\n",
            "Epoch:46\n",
            "Train Loss:0.221475|Train Acc:92.651055%\n",
            "Test loss: 0.34294 | Test accuracy: 88.28%\n",
            "\n",
            "Epoch:47\n",
            "New best test loss is 88.27627388535032. Model Saved\n",
            "Train Loss:0.221179|Train Acc:92.710997%\n",
            "Test loss: 0.37237 | Test accuracy: 87.08%\n",
            "\n",
            "Epoch:48\n",
            "Train Loss:0.218204|Train Acc:92.689019%\n",
            "Test loss: 0.33471 | Test accuracy: 88.68%\n",
            "\n",
            "Epoch:49\n",
            "New best test loss is 88.6843152866242. Model Saved\n",
            "Last model is saved with test loss:88.6843152866242\n",
            "Train time on cuda: 4225.827 seconds\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "4225.827475759999"
            ]
          },
          "metadata": {},
          "execution_count": 34
        }
      ]
    }
  ]
}
